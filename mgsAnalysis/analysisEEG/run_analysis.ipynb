{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import socket\n",
    "import mne\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "p = {}\n",
    "if hostname == 'syndrome' or hostname == 'zod.psych.nyu.edu' or hostname == 'zod':\n",
    "    p['datc'] = '/d/DATC/datc/MD_TMS_EEG'\n",
    "else:\n",
    "    p['datc'] = '/Users/mrugankdake/Documents/Clayspace/EEG_TMS/datc/MD_TMS_EEG'\n",
    "p['data'] = p['datc'] + '/data'\n",
    "p['analysis'] = p['datc'] + '/analysis'\n",
    "p['EEGfiles'] = p['datc'] + '/EEGfiles'\n",
    "p['meta'] = p['analysis'] + '/meta_analysis'\n",
    "p['df_fname'] = os.path.join(p['meta'], 'calib_filtered.csv')\n",
    "p['master_evoked'] = os.path.join(p['EEGfiles'], 'masterTFR_evoked.mat')\n",
    "p['master_induced'] = os.path.join(p['EEGfiles'], 'masterTFR_induced.mat')\n",
    "p['training_data'] = os.path.join(p['EEGfiles'], 'training_data.npy')\n",
    "p['chan_names'] = os.path.join(p['EEGfiles'], 'chan_names.npy')\n",
    "p['trl_matrix'] = os.path.join(p['EEGfiles'], 'trl_matrix.npy')\n",
    "\n",
    "# Load up summary meta-data\n",
    "summary_df = pd.read_csv(os.path.join(p['analysis'] + '/EEG_TMS_meta_Summary.csv'))\n",
    "All_metadata = {row['Subject ID']: row for _, row in summary_df.iterrows()}\n",
    "\n",
    "# Load up behavioral data\n",
    "df_behav = pd.read_csv(p['df_fname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (100,) into shape (1189,62,146)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 86\u001b[0m\n\u001b[1;32m     83\u001b[0m             current_trial_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m num_trials\n\u001b[1;32m     85\u001b[0m             trl_mat \u001b[38;5;241m=\u001b[39m trl_dict[cond][ss][dd]\n\u001b[0;32m---> 86\u001b[0m             \u001b[43mdata_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcond_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mss_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdd_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m trl_mat\n\u001b[1;32m     89\u001b[0m np\u001b[38;5;241m.\u001b[39msave(p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtraining_data\u001b[39m\u001b[38;5;124m'\u001b[39m], data_matrix)\n\u001b[1;32m     90\u001b[0m np\u001b[38;5;241m.\u001b[39msave(p[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchan_names\u001b[39m\u001b[38;5;124m'\u001b[39m], chan_list)\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (100,) into shape (1189,62,146)"
     ]
    }
   ],
   "source": [
    "sub_list = [1]\n",
    "day_list = [1, 2, 3]\n",
    "conditions = ['pin', 'pout', 'ain', 'aout']\n",
    "\n",
    "data_dict = {cond: {ss: {dd: [] for dd in day_list} for ss in sub_list} for cond in conditions}\n",
    "trl_dict = {cond: {ss: {dd: [] for dd in day_list} for ss in sub_list} for cond in conditions}\n",
    "\n",
    "subject_day_info = []\n",
    "freq_band = (8, 12)\n",
    "time_band = (-1, 4.5)\n",
    "ch_count = None\n",
    "time_points = None\n",
    "tr_count = 0\n",
    "\n",
    "tfr_type = 'evoked'\n",
    "\n",
    "if os.path.exists(p['training_data']):\n",
    "    data_matrix = np.load(p['training_data'])\n",
    "    chan_list = np.load(p['chan_names'])\n",
    "    trl_matrix = np.load(p['trl_matrix'])\n",
    "else:\n",
    "    for cond_idx, cond in enumerate(conditions):\n",
    "        for ss in sub_list:\n",
    "            for dd in day_list:\n",
    "                this_fname = os.path.join(p['EEGfiles'], f'sub{ss:02}', f'day{dd:02}', f'sub{ss:02}_day{dd:02}_TFR_'+tfr_type+'.mat')\n",
    "                trl_idx_fname = os.path.join(p['EEGfiles'], f'sub{ss:02}', f'day{dd:02}', f'sub{ss:02}_day{dd:02}_trl_idx.mat')\n",
    "                trl_idx = loadmat(trl_idx_fname)['trl_idx'][0][0][cond_idx]\n",
    "                trl_idx = np.asarray(trl_idx).T[0]\n",
    "                trl_dict[cond][ss][dd] = trl_idx\n",
    "                with h5py.File(this_fname, 'r') as f:\n",
    "                    # Load up power-spectrum\n",
    "                    powspctrm = np.array(f['POW'][cond]['powspctrm'])\n",
    "                    # Load up channel labels\n",
    "                    ch_refs = f['POW'][cond]['label'][0]\n",
    "                    ch_labels = []\n",
    "                    for ref in ch_refs:\n",
    "                        label_data = f[ref]\n",
    "                        label = ''.join(chr(c[0]) for c in label_data)\n",
    "                        ch_labels.append(label)\n",
    "                    # Load up time and frequency\n",
    "                    time = np.array(f['POW'][cond]['time'])\n",
    "                    freqs = np.array(f['POW'][cond]['freq'])\n",
    "                    \n",
    "                    # Create order of channel labels first time running this\n",
    "                    if tr_count == 0:\n",
    "                        chan_list = ch_labels\n",
    "                    \n",
    "                    # Reorder data for channel indices are different from the one in first dataset\n",
    "                    channel_indices = [chan_list.index(ch) for ch in ch_labels]\n",
    "                    powspctrm = powspctrm[:, :, channel_indices, :]\n",
    "\n",
    "                    # Slice along the time of interest -1 to 4.5 seconds\n",
    "                    time = np.array(f['POW'][cond]['time'])\n",
    "                    time_band_indices = np.where((time >= time_band[0]) & (time <= time_band[1]))[0]\n",
    "                    powspctrm = powspctrm[time_band_indices, :, :, :]\n",
    "\n",
    "                    # Average over the alpha band\n",
    "                    freqs = np.array(f['POW'][cond]['freq'])\n",
    "                    freq_band_indices = np.where((freqs >= freq_band[0]) & (freqs <= freq_band[1]))[0]\n",
    "                    powspctrm_avg = np.mean(powspctrm[:, freq_band_indices, :, :], axis=1)\n",
    "\n",
    "                    # Reorder X_avg in the shape (trials, channels, time)\n",
    "                    powspctrm_avg = np.transpose(powspctrm_avg, (2, 1, 0))\n",
    "\n",
    "                    data_dict[cond][ss][dd] = powspctrm_avg\n",
    "\n",
    "                    if ch_count is None:\n",
    "                        ch_count = powspctrm_avg.shape[1]\n",
    "                    if time_points is None:\n",
    "                        time_points = powspctrm_avg.shape[2]\n",
    "                    tr_count += powspctrm_avg.shape[0]\n",
    "\n",
    "    data_matrix = np.zeros((len(conditions), len(sub_list), len(day_list), tr_count, ch_count, time_points))\n",
    "    trl_matrix = np.zeros((len(conditions), len(sub_list), len(day_list), tr_count))\n",
    "    current_trial_index = 0\n",
    "\n",
    "    for cond_idx, cond in enumerate(conditions):\n",
    "        for ss_idx, ss in enumerate(sub_list):\n",
    "            for dd_idx, dd in enumerate(day_list):\n",
    "                data = data_dict[cond][ss][dd]\n",
    "                num_trials = data.shape[0]\n",
    "                data_matrix[cond_idx, ss_idx, dd_idx, current_trial_index:current_trial_index+num_trials, :, :] = data\n",
    "                current_trial_index += num_trials\n",
    "\n",
    "                trl_mat = trl_dict[cond][ss][dd]\n",
    "                data_matrix[cond_idx, ss_idx, dd_idx, :] = trl_mat\n",
    "\n",
    "\n",
    "    np.save(p['training_data'], data_matrix)\n",
    "    np.save(p['chan_names'], chan_list)\n",
    "    np.save(p['trl_matrix'], trl_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 1, 1, 398, 62, 146)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "trl_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chan_list.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegmne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
