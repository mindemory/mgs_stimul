{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import socket\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "p = {}\n",
    "if hostname == 'syndrome' or hostname == 'zod.psych.nyu.edu' or hostname == 'zod':\n",
    "    p['datd'] = '/d/DATD/datd/MD_TMS_EEG'\n",
    "else:\n",
    "    p['datd'] = '/Users/mrugankdake/Documents/Clayspace/EEG_TMS/datd/MD_TMS_EEG'\n",
    "p['data'] = p['datd'] + '/data'\n",
    "p['analysis'] = p['datd'] + '/analysis'\n",
    "p['EEGfiles'] = p['datd'] + '/EEGfiles'\n",
    "p['meta'] = p['analysis'] + '/meta_analysis'\n",
    "p['df_fname'] = os.path.join(p['meta'], 'calib_filtered.csv')\n",
    "p['ALI_evoked'] = os.path.join(p['EEGfiles'], 'ALI_evoked_basecorr0.mat')\n",
    "p['ALI_induced'] = os.path.join(p['EEGfiles'], 'ALI_induced_basecorr0.mat')\n",
    "p['mCDA'] = os.path.join(p['EEGfiles'], 'CDA.mat')\n",
    "p['training_data'] = os.path.join(p['EEGfiles'], 'training_data.npy')\n",
    "# Load up summary meta-data\n",
    "summary_df = pd.read_csv(os.path.join(p['analysis'] + '/EEG_TMS_meta_Summary.csv'))\n",
    "All_metadata = {row['Subject ID']: row for _, row in summary_df.iterrows()}\n",
    "\n",
    "# Load up behavioral data\n",
    "df_behav = pd.read_csv(p['df_fname'])\n",
    "df_behav['trl_idx'] = df_behav['rnum'] * df_behav['tnum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up ALI evoked and induced\n",
    "with h5py.File(p['ALI_evoked'], 'r') as f:\n",
    "    X_evoked = np.array(f['mALI']).T\n",
    "    y_evoked = np.array(f['trl_mat']).T\n",
    "yevoked_df = pd.DataFrame(y_evoked, columns = ['subjID', 'day', 'istms', 't_type', 'trl_idx'], dtype='int')\n",
    "\n",
    "with h5py.File(p['ALI_induced'], 'r') as f:\n",
    "    X_induced = np.array(f['mALI']).T\n",
    "    y_induced = np.array(f['trl_mat']).T\n",
    "yinduced_df = pd.DataFrame(y_induced, columns = ['subjID', 'day', 'istms', 't_type', 'trl_idx'], dtype='int')\n",
    "\n",
    "# Load up the time array\n",
    "with h5py.File(os.path.join(p['EEGfiles'], 'sub01/day01/sub01_day01_TFR_evoked.mat')) as f:\n",
    "    time_array = np.array(f['POW']['pin']['time'])\n",
    "\n",
    "# Create data with just trials that were retained after both behavioral and EEG trial-rejection\n",
    "master_df = pd.merge(df_behav.reset_index(), yevoked_df.drop(columns=['istms']).reset_index(), on=['subjID', 'day', 'trl_idx'], how='inner', indicator=True)\n",
    "idx_behav = master_df['index_x'].tolist()\n",
    "idx_ALI = master_df['index_y'].tolist()\n",
    "master_df = master_df.drop(columns=['index_x', 'Unnamed: 0', 'index_y', '_merge'])\n",
    "Xcommon_evoked = X_evoked[idx_ALI, :]\n",
    "Xcommon_induced = X_induced[idx_ALI, :]\n",
    "\n",
    "# Make a list of different trial-types\n",
    "trial_types = ['pin', 'pout', 'ain', 'aout']\n",
    "tms_cond = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ALI average per subject\n",
    "sub_list = yevoked_df['subjID'].unique()\n",
    "ALI_evoked = np.zeros((len(tms_cond), len(trial_types), len(sub_list), len(time_array)))\n",
    "ALI_induced = np.zeros((len(tms_cond), len(trial_types), len(sub_list), len(time_array)))\n",
    "for ii, cond in enumerate(tms_cond):\n",
    "    for jj, t_type in enumerate(trial_types):\n",
    "        idx = yevoked_df.loc[(yevoked_df['istms'] == cond) & (yevoked_df['t_type'] == jj+1)].index\n",
    "        this_df = yevoked_df.iloc[idx].reset_index(drop=True)\n",
    "        this_X_evoked = X_evoked[idx, :]\n",
    "        this_X_induced = X_induced[idx, :]\n",
    "        for kk in range(len(sub_list)):\n",
    "            this_idx = this_df.index[this_df['subjID'] == sub_list[kk]].tolist()\n",
    "            ALI_evoked[ii, jj, kk, :] = np.nanmean(this_X_evoked[this_idx, :], 0)\n",
    "            ALI_induced[ii, jj, kk, :] = np.nanmean(this_X_induced[this_idx, :], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALIs for evoked vs induced for No TMS\n",
    "lim_val = 0.3\n",
    "f, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for jj, ax in zip([0,1,2,3], axs.ravel()):\n",
    "    y1 = np.nanmean(ALI_evoked[0, jj, :, :], 0)\n",
    "    y2 = np.nanmean(ALI_induced[0, jj, :, :], 0)\n",
    "    y1_err = np.nanstd(ALI_evoked[0, jj, :, :], 0)/np.sqrt(len(sub_list))\n",
    "    y2_err = np.nanstd(ALI_induced[0, jj, :, :], 0)/np.sqrt(len(sub_list))\n",
    "    ax.plot(time_array, y1, 'k-', label='evoked')\n",
    "    ax.plot(time_array, y2, 'b-', label='induced')\n",
    "    ax.fill_between(time_array[:,0], y1-y1_err, y1+y1_err, alpha=0.5, linewidth=0, color='k')\n",
    "    ax.fill_between(time_array[:,0], y2-y2_err, y2+y2_err, alpha=0.5, linewidth=0, color='b')\n",
    "    ax.plot(time_array, np.zeros(len(time_array)), 'k--')\n",
    "    ax.plot([0, 0], [-lim_val, lim_val], 'g-')\n",
    "    ax.plot([4.5, 4.5], [-lim_val, lim_val], 'g-')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(time_array[0], time_array[-1])\n",
    "    ax.set_ylim(-lim_val, lim_val)\n",
    "    ax.set_ylabel('ALI')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_title(trial_types[jj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALIs for evoked for No TMS vs TMS\n",
    "lim_val = 0.3\n",
    "f, axs = plt.subplots(2, 2, figsize=(10, 10))\n",
    "for jj, ax in zip([0,1,2,3], axs.ravel()):\n",
    "    y1 = np.nanmean(ALI_evoked[0, jj, :, :], 0)\n",
    "    y2 = np.nanmean(ALI_evoked[1, jj, :, :], 0)\n",
    "    y1_err = np.nanstd(ALI_evoked[0, jj, :, :], 0)/np.sqrt(len(sub_list))\n",
    "    y2_err = np.nanstd(ALI_evoked[1, jj, :, :], 0)/np.sqrt(len(sub_list))\n",
    "    ax.plot(time_array, y1, 'b-', label='no tms')\n",
    "    ax.plot(time_array, y2, 'r-', label='tms')\n",
    "    ax.fill_between(time_array[:,0], y1-y1_err, y1+y1_err, alpha=0.5, linewidth=0, color='b')\n",
    "    ax.fill_between(time_array[:,0], y2-y2_err, y2+y2_err, alpha=0.5, linewidth=0, color='r')\n",
    "    ax.plot(time_array, np.zeros(len(time_array)), 'k--')\n",
    "    ax.plot([0, 0], [-lim_val, lim_val], 'g-')\n",
    "    ax.plot([4.5, 4.5], [-lim_val, lim_val], 'g-')\n",
    "    ax.legend()\n",
    "    ax.set_xlim(time_array[0], time_array[-1])\n",
    "    ax.set_ylim(-lim_val, lim_val)\n",
    "    ax.set_ylabel('ALI')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_title(trial_types[jj])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALIs for evoked for No TMS vs TMS\n",
    "lim_val = 0.3\n",
    "N = 8\n",
    "cols = 2#int(np.ceil(np.sqrt(N)))\n",
    "rows = int(np.ceil(N / cols))\n",
    "f, axs = plt.subplots(rows, cols, figsize=(10, 20))\n",
    "plt_counter = 0\n",
    "for side in ['Left', 'Right']:\n",
    "    for jj in [0, 1, 2, 3]:\n",
    "        ax = axs[plt_counter // cols, plt_counter % cols]\n",
    "        y1_holder = np.empty((0, ALI_evoked.shape[3]))\n",
    "        y2_holder = np.empty((0, ALI_evoked.shape[3]))\n",
    "        counter = 0\n",
    "        for i, ss in enumerate(sub_list):\n",
    "            if All_metadata[ss]['Hemisphere stimulated'] == side:\n",
    "                slice_y1 = ALI_evoked[0, jj, i, :]\n",
    "                slice_y2 = ALI_evoked[1, jj, i, :]\n",
    "                y1_holder = np.concatenate((y1_holder, slice_y1[np.newaxis, :]), axis=0)\n",
    "                y2_holder = np.concatenate((y2_holder, slice_y2[np.newaxis, :]), axis=0)\n",
    "                counter += 1\n",
    "        y1 = np.nanmean(y1_holder, 0)\n",
    "        y2 = np.nanmean(y2_holder, 0)\n",
    "        y1_err = np.nanstd(y1_holder, 0)/np.sqrt(counter)\n",
    "        y2_err = np.nanstd(y2_holder, 0)/np.sqrt(counter)\n",
    "        ax.plot(time_array, y1, 'b-', label='no tms')\n",
    "        ax.plot(time_array, y2, 'r-', label='tms')\n",
    "        ax.fill_between(time_array[:,0], y1-y1_err, y1+y1_err, alpha=0.5, linewidth=0, color='b')\n",
    "        ax.fill_between(time_array[:,0], y2-y2_err, y2+y2_err, alpha=0.5, linewidth=0, color='r')\n",
    "        ax.plot(time_array, np.zeros(len(time_array)), 'k--')\n",
    "        ax.plot([0, 0], [-lim_val, lim_val], 'g-')\n",
    "        ax.plot([4.5, 4.5], [-lim_val, lim_val], 'g-')\n",
    "        ax.legend()\n",
    "        ax.set_xlim(time_array[0], time_array[-1])\n",
    "        ax.set_ylim(-lim_val, lim_val)\n",
    "        ax.set_ylabel('ALI')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_title(side + ': ' + trial_types[jj])\n",
    "        plt_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ALIs for evoked for No TMS vs TMS\n",
    "lim_val = 0.5\n",
    "N = 17*4\n",
    "cols = 4#int(np.ceil(np.sqrt(N)))\n",
    "rows = int(np.ceil(N / cols))\n",
    "f, axs = plt.subplots(rows, cols, figsize=(20, 100))\n",
    "plt_counter = 0\n",
    "for i, ss in enumerate(sub_list):\n",
    "    for jj in [0, 1, 2, 3]:\n",
    "        ax = axs[plt_counter // cols, plt_counter % cols]\n",
    "        y1 = ALI_induced[0, jj, i, :]\n",
    "        y2 = ALI_induced[1, jj, i, :]\n",
    "\n",
    "        ax.plot(time_array, y1, 'b-', label='no tms')\n",
    "        ax.plot(time_array, y2, 'r-', label='tms')\n",
    "        \n",
    "        ax.plot(time_array, np.zeros(len(time_array)), 'k--')\n",
    "        ax.plot([0, 0], [-lim_val, lim_val], 'g-')\n",
    "        ax.plot([4.5, 4.5], [-lim_val, lim_val], 'g-')\n",
    "        ax.legend()\n",
    "        ax.set_xlim(time_array[0], time_array[-1])\n",
    "        ax.set_ylim(-lim_val, lim_val)\n",
    "        ax.set_ylabel('ALI')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_title(str(ss) + ': ' + trial_types[jj])\n",
    "        plt_counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_pin_ntms = master_df.loc[(master_df['istms']==0) & (master_df['t_type']==1)].index\n",
    "mask = (time_array >= 0) & (time_array <= 4)\n",
    "tidx = np.where(mask)[0]\n",
    "X_temp = Xcommon_evoked[idx_pin_ntms, :]\n",
    "X = X_temp[:, tidx]\n",
    "this_df = master_df.iloc[idx_pin_ntms].reset_index(drop=True)\n",
    "y = this_df['ierr']\n",
    "\n",
    "n_trials, n_timepoints = X.shape\n",
    "mse_per_timepoint = np.zeros(n_timepoints) \n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Iterate over each time-point\n",
    "for t in range(n_timepoints):\n",
    "    y_preds = np.zeros(n_trials)\n",
    "    y_true = y.copy()\n",
    "\n",
    "    for train_index, test_index in loo.split(X):\n",
    "        X_train, X_test = X[train_index, t].reshape(-1, 1), X[test_index, t].reshape(-1, 1)\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_preds[test_index] = y_pred\n",
    "\n",
    "    mse_per_timepoint[t] = mean_squared_error(y_true, y_preds)\n",
    "\n",
    "# n_permutations = 1000\n",
    "# n_timepoints = X.shape[1]\n",
    "# perm_mse = np.zeros((n_permutations, n_timepoints))\n",
    "\n",
    "# for p in range(n_permutations):\n",
    "#     y_perm = np.random.permutation(y)\n",
    "#     for t in range(n_timepoints):\n",
    "#         y_preds = np.zeros(n_trials)\n",
    "#         y_true = y.copy()\n",
    "\n",
    "#         for train_index, test_index in loo.split(X):\n",
    "#             X_train, X_test = X[train_index, t].reshape(-1, 1), X[test_index, t].reshape(-1, 1)\n",
    "#             y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "#             model = LinearRegression()\n",
    "#             model.fit(X_train, y_train)\n",
    "\n",
    "#             y_pred = model.predict(X_test)\n",
    "#             y_preds[test_index] = y_pred\n",
    "\n",
    "#         perm_mse[p, t] = mean_squared_error(y_true, y_preds)\n",
    "# p_values = np.mean(perm_mse <= mse_per_timepoint, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array_relevant = time_array[tidx]\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_array_relevant, mse_per_timepoint, marker='o')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('MSE per Time-point')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "idx_ntms = master_df.loc[(master_df['istms']==0)].index\n",
    "mask = (time_array >= 0) & (time_array <= 4)\n",
    "tidx = np.where(mask)[0]\n",
    "X_temp = Xcommon_evoked[idx_ntms, :]\n",
    "X = X_temp[:, tidx]\n",
    "this_df = master_df.iloc[idx_ntms].reset_index(drop=True)\n",
    "y = this_df['t_type']\n",
    "#y = y.apply(lambda x: 1 if x in [1, 2] else 30)\n",
    "n_trials, n_timepoints = X.shape\n",
    "accuracy_per_timepoint = np.zeros(n_timepoints)\n",
    "\n",
    "# loo = LeaveOneOut()\n",
    "n_splits = 10\n",
    "kf = KFold(n_splits=n_splits)\n",
    "\n",
    "accuracy_per_timepoint = np.zeros(n_timepoints)\n",
    "\n",
    "# Iterate over each time-point\n",
    "for t in range(n_timepoints):\n",
    "    y_preds = []\n",
    "\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index, t].reshape(-1, 1), X[test_index, t].reshape(-1, 1)\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "        model = LogisticRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_preds.extend(model.predict(X_test))\n",
    "\n",
    "    accuracy_per_timepoint[t] = accuracy_score(y, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_array_relevant = time_array[tidx]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_array_relevant, accuracy_per_timepoint, marker='o', label='Decoding Accuracy')\n",
    "plt.axhline(y=0.25, color='k', linestyle='--', label='Chance Level (25%)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Decoding Accuracy per Time-point')\n",
    "plt.legend()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_matrix = np.zeros((n_timepoints, n_timepoints))\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Loop over each time-point for training\n",
    "for train_time in range(n_timepoints):\n",
    "    X_train_time = X[:, train_time].reshape(-1, 1)\n",
    "\n",
    "    # Loop over each time-point for testing\n",
    "    for test_time in range(n_timepoints):\n",
    "        y_preds = np.zeros(n_trials)\n",
    "        X_test_time = X[:, test_time].reshape(-1, 1)\n",
    "\n",
    "        for train_index, test_index in loo.split(X_train_time):\n",
    "            model = LogisticRegression()\n",
    "            model.fit(X_train_time[train_index], y[train_index])\n",
    "            y_pred = model.predict(X_test_time[test_index])\n",
    "            y_preds[test_index] = y_pred\n",
    "\n",
    "        accuracy_matrix[train_time, test_time] = accuracy_score(y, y_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(accuracy_matrix, annot=True, cmap='viridis')\n",
    "plt.xlabel('Test Time Point')\n",
    "plt.ylabel('Train Time Point')\n",
    "plt.title('Time-by-Time Generalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contralateral Delay Activity (CDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load up ALI evoked and induced\n",
    "with h5py.File(p['mCDA'], 'r') as f:\n",
    "    mCDA = np.array(f['mCDA']).T\n",
    "\n",
    "with h5py.File(os.path.join(p['EEGfiles'], 'sub01/day01/sub01_day01_erp.mat')) as f:\n",
    "    tarray_erp = np.array(f['ERP']['pin']['time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CDAs for evoked for No TMS vs TMS\n",
    "lim_val = 2\n",
    "N = 8\n",
    "cols = 4#int(np.ceil(np.sqrt(N)))\n",
    "rows = int(np.ceil(N / cols))\n",
    "f, axs = plt.subplots(rows, cols, figsize=(20, 10))\n",
    "plt_counter = 0\n",
    "for tms_cond in [0, 1]:\n",
    "    for jj in [0, 1, 2, 3]:\n",
    "        ax = axs[plt_counter // cols, plt_counter % cols]\n",
    "        y1_holder = np.empty((0, len(tarray_erp)))\n",
    "        for i, ss in enumerate(sub_list):\n",
    "            if tms_cond == 0:\n",
    "                dd_idx = int(All_metadata[ss]['No TMS day']-1)\n",
    "                y1 = mCDA[i, dd_idx, jj, :]\n",
    "            else:\n",
    "                nodd_idx = int(All_metadata[ss]['No TMS day']-1)\n",
    "                dd_idx = [dd for dd in [0,1,2] if dd!=nodd_idx]\n",
    "                y1 = np.mean(mCDA[i, dd_idx, jj, :], axis = 0)\n",
    "            y1_holder = np.concatenate((y1_holder, y1[np.newaxis, :]), axis=0)\n",
    "        y1_holder = np.nanmean(y1_holder, axis = 0)\n",
    "        win_size = 20 #samples\n",
    "        tarray_plot = np.convolve(tarray_erp[:, 0], np.ones(win_size)/win_size, mode='valid')\n",
    "        y1_plot = np.convolve(y1_holder, np.ones(win_size)/win_size, mode='valid')\n",
    "        if tms_cond == 0:\n",
    "            ax.plot(tarray_plot, y1_plot, 'b-', label=tms_cond)  \n",
    "        else:\n",
    "            ax.plot(tarray_plot, y1_plot, 'r-', label=tms_cond)      \n",
    "        ax.plot(tarray_plot, np.zeros(len(tarray_plot)), 'k--')\n",
    "        ax.plot([0, 0], [-lim_val, lim_val], 'g-')\n",
    "        ax.plot([4.5, 4.5], [-lim_val, lim_val], 'g-')\n",
    "        ax.legend()\n",
    "        ax.set_xlim(tarray_plot[0], tarray_plot[-1])\n",
    "        ax.set_ylim(-lim_val, lim_val)\n",
    "        ax.set_ylabel('CDA')\n",
    "        ax.set_xlabel('Time (s)')\n",
    "        ax.set_title('CDA: ' + trial_types[jj])\n",
    "        plt_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegmne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
