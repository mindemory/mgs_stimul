{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import socket\n",
    "\n",
    "hostname = socket.gethostname()\n",
    "p = {}\n",
    "if hostname == 'syndrome' or hostname == 'zod.psych.nyu.edu' or hostname == 'zod':\n",
    "    p['datc'] = '/d/DATC/datc/MD_TMS_EEG'\n",
    "else:\n",
    "    p['datc'] = '/Users/mrugankdake/Documents/Clayspace/EEG_TMS/datc/MD_TMS_EEG'\n",
    "p['data'] = p['datc'] + '/data'\n",
    "p['analysis'] = p['datc'] + '/analysis'\n",
    "p['EEGfiles'] = p['datc'] + '/EEGfiles'\n",
    "p['meta'] = p['analysis'] + '/meta_analysis'\n",
    "p['df_fname'] = os.path.join(p['meta'], 'calib_filtered.csv')\n",
    "p['ALI_evoked'] = os.path.join(p['EEGfiles'], 'ALI_evoked.mat')\n",
    "p['ALI_induced'] = os.path.join(p['EEGfiles'], 'ALI_induced.mat')\n",
    "p['training_data'] = os.path.join(p['EEGfiles'], 'training_data.npy')\n",
    "# Load up summary meta-data\n",
    "summary_df = pd.read_csv(os.path.join(p['analysis'] + '/EEG_TMS_meta_Summary.csv'))\n",
    "All_metadata = {row['Subject ID']: row for _, row in summary_df.iterrows()}\n",
    "\n",
    "# Load up behavioral data\n",
    "df_behav = pd.read_csv(p['df_fname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(p['ALI_evoked'], 'r') as f:\n",
    "    X = np.array(f['mALI']).T\n",
    "    y = np.array(f['trl_mat']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>20066.000000</td>\n",
       "      <td>20066.000000</td>\n",
       "      <td>20066.000000</td>\n",
       "      <td>20066.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.857271</td>\n",
       "      <td>0.664407</td>\n",
       "      <td>2.503588</td>\n",
       "      <td>200.228396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.285075</td>\n",
       "      <td>0.472209</td>\n",
       "      <td>1.118368</td>\n",
       "      <td>114.994192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>101.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>299.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>422.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3\n",
       "count  20066.000000  20066.000000  20066.000000  20066.000000\n",
       "mean      14.857271      0.664407      2.503588    200.228396\n",
       "std        8.285075      0.472209      1.118368    114.994192\n",
       "min        1.000000      0.000000      1.000000      1.000000\n",
       "25%        7.000000      0.000000      2.000000    101.000000\n",
       "50%       15.000000      1.000000      3.000000    200.000000\n",
       "75%       23.000000      1.000000      4.000000    299.000000\n",
       "max       27.000000      1.000000      4.000000    422.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_df = pd.DataFrame(y, columns = ['subjID', 'day', 'istms', 't_type', 'trl_idx'])\n",
    "y_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 3, 1189, 62, 146)\n"
     ]
    }
   ],
   "source": [
    "sub_list = [1]\n",
    "day_list = [1, 2, 3]\n",
    "conditions = ['pin', 'pout', 'ain', 'aout']\n",
    "\n",
    "data_dict = {cond: {ss: {dd: [] for dd in day_list} for ss in sub_list} for cond in conditions}\n",
    "\n",
    "subject_day_info = []\n",
    "freq_band = (8, 12)\n",
    "time_band = (-1, 4.5)\n",
    "ch_count = None\n",
    "time_points = None\n",
    "tr_count = 0\n",
    "\n",
    "tfr_type = 'evoked'\n",
    "\n",
    "if os.path.exists(p['training_data']):\n",
    "    data_matrix = np.load(p['training_data'])\n",
    "else:\n",
    "    for cond in conditions:\n",
    "        for ss in sub_list:\n",
    "            for dd in day_list:\n",
    "                this_fname = os.path.join(p['EEGfiles'], f'sub{ss:02}', f'day{dd:02}', f'sub{ss:02}_day{dd:02}_TFR_'+tfr_type+'.mat')\n",
    "                with h5py.File(this_fname, 'r') as f:\n",
    "                    # Load the time-frequency data\n",
    "                    powspctrm = np.array(f['POW'][cond]['powspctrm'])\n",
    "                    ch_labels = np.array(f['POW'][cond]['label']).astype(str)\n",
    "                    # Create order of channel labels first time running this\n",
    "                    if tr_count == 0:\n",
    "                        standard_labels = ch_labels\n",
    "                    \n",
    "                    # Reorder data for channel indices are different from the one in first dataset\n",
    "                    channel_indices = np.array([np.where(standard_labels == ch)[0][0] for ch in ch_labels])\n",
    "                    powspctrm = powspctrm[:, :, channel_indices, :]\n",
    "\n",
    "                    # Slice along the time of interest -1 to 4.5 seconds\n",
    "                    time = np.array(f['POW'][cond]['time'])\n",
    "                    time_band_indices = np.where((time >= time_band[0]) & (time <= time_band[1]))[0]\n",
    "                    powspctrm = powspctrm[time_band_indices, :, :, :]\n",
    "\n",
    "                    # Average over the alpha band\n",
    "                    freqs = np.array(f['POW'][cond]['freq'])\n",
    "                    freq_band_indices = np.where((freqs >= freq_band[0]) & (freqs <= freq_band[1]))[0]\n",
    "                    powspctrm_avg = np.mean(powspctrm[:, freq_band_indices, :, :], axis=1)\n",
    "\n",
    "                    # Reorder X_avg in the shape (trials, channels, time)\n",
    "                    powspctrm_avg = np.transpose(powspctrm_avg, (2, 1, 0))\n",
    "\n",
    "                    data_dict[cond][ss][dd] = powspctrm_avg\n",
    "\n",
    "                    if ch_count is None:\n",
    "                        ch_count = powspctrm_avg.shape[1]\n",
    "                    if time_points is None:\n",
    "                        time_points = powspctrm_avg.shape[2]\n",
    "                    tr_count += powspctrm_avg.shape[0]\n",
    "\n",
    "    data_matrix = np.zeros((len(conditions), len(sub_list), len(day_list), tr_count, ch_count, time_points))\n",
    "    current_trial_index = 0\n",
    "\n",
    "    for cond_idx, cond in enumerate(conditions):\n",
    "        for ss_idx, ss in enumerate(sub_list):\n",
    "            for dd_idx, dd in enumerate(day_list):\n",
    "                data = data_dict[cond][ss][dd]\n",
    "                num_trials = data.shape[0]\n",
    "                data_matrix[cond_idx, ss_idx, dd_idx, current_trial_index:current_trial_index+num_trials, :, :] = data\n",
    "                current_trial_index += num_trials\n",
    "\n",
    "    np.save(p['training_data'], data_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa = np.transpose(X_avg, (2, 1, 0))\n",
    "print(aa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eegmne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
