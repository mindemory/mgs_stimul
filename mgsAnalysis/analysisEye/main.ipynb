{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading existing dataframe! If this is not desired, delete the current mater_df.csv\n",
      "Loading existing dataframe! If this is not desired, delete the current mater_df.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import generate_masterdf as gm\n",
    "from preproc_funcs import *\n",
    "from generate_plots import *\n",
    "from helpers import *\n",
    "from scipy import stats\n",
    "\n",
    "pd.set_option(\"display.max.columns\", None)\n",
    "pd.set_option(\"display.precision\", 4)\n",
    "\n",
    "msize = 10\n",
    "axes_fontsize = 14\n",
    "title_fontsize = 18\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing data features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trials removed = 4686 = 14.25% \n",
      "Timing issues = 65 = 0.2% \n",
      "No saccades detected issues = 2926 = 8.9% \n",
      "Reaction time issues = 178 = 0.54% \n",
      "Large errors = 1517 = 4.61% \n",
      "\n",
      "Trials removed = 4009 = 12.19% \n",
      "Timing issues = 65 = 0.2% \n",
      "No saccades detected issues = 2248 = 6.84% \n",
      "Reaction time issues = 517 = 1.57% \n",
      "Large errors = 1179 = 3.59% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading the data as a dataframe\n",
    "df_calib_orig = gm.master_calib_df\n",
    "df_nocalib_orig = gm.master_nocalib_df\n",
    "\n",
    "# Add additonal error metrics\n",
    "df_calib_orig = add_metrics(df_calib_orig)\n",
    "df_nocalib_orig = add_metrics(df_nocalib_orig)\n",
    "\n",
    "# Preprocess and filter both datasets\n",
    "df_calib, df_calib_all5 = filter_data(df_calib_orig)\n",
    "df_nocalib, df_nocalib_all5 = filter_data(df_nocalib_orig)\n",
    "\n",
    "sub_list_all5 = np.unique(df_calib_all5['subjID'].values)\n",
    "sub_list = np.unique(df_calib['subjID'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose what you wanna see\n",
    "print('Dataframe description')\n",
    "df_calib.info()\n",
    "df_calib.describe(include=object)\n",
    "df_nocalib.info()\n",
    "df_nocalib.describe(include=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting features\n",
    "df_to_visualize = df_calib\n",
    "small_df = df_to_visualize.sample(frac=0.1, random_state=42)\n",
    "\n",
    "cat_cols = df_calib.select_dtypes(include=['object']).columns\n",
    "numer_cols = ['age', 'weight', 'TarX', 'TarY', 'isaccX', 'isaccY', 'fsaccX',\n",
    "       'fsaccY', 'nsacc', 'isacc_rt', 'fsacc_rt', 'isacc_peakvel',\n",
    "       'fsacc_peakvel', 'ierrX', 'ierrY', 'ferrX',\n",
    "       'ferrY', 'ierr', 'ferr', 'igain', 'fgain', 'eccentricity', 'polang', 'PT', 'StimIntensity',\n",
    "       'ipea', 'fpea', 'iang', 'fang', 'itheta', 'iradial', 'itangential',\n",
    "       'ftheta', 'fradial', 'ftangential', 'ierr_threshold', 'ferr_threshold']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize numerical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 40))\n",
    "for i, col in enumerate(numer_cols):\n",
    "    plt.subplot(8, 5, i + 1)\n",
    "    sns.histplot(x=col, data=small_df)\n",
    "    plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for correlation in data\n",
    "plt.figure(figsize=(20, 20))\n",
    "corr_matrix = df_to_visualize[numer_cols].corr()\n",
    "mask = (corr_matrix > 0.25) | (corr_matrix < -0.25)\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', mask = ~mask,\n",
    "            xticklabels=corr_matrix.columns, yticklabels=corr_matrix.columns)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(cat_cols):\n",
    "    plt.subplot(2, 4, i + 1)\n",
    "    sns.countplot(x=col, data=df_calib)\n",
    "    plt.title(f'Count of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        subjID      day      age    weight  eegsize       PT  StimIntensity  \\\n",
      "count  21.0000  21.0000  21.0000   21.0000  21.0000  21.0000        21.0000   \n",
      "mean   14.4286   4.7143  28.7143   66.3333  57.1429  45.8095        50.9048   \n",
      "std     7.9219   0.7171   7.3153   13.6247   1.7403   6.1775         6.7743   \n",
      "min     1.0000   3.0000  21.0000   46.0000  56.0000  35.0000        40.0000   \n",
      "25%     8.0000   5.0000  25.0000   57.0000  56.0000  42.0000        47.0000   \n",
      "50%    14.0000   5.0000  27.0000   64.0000  56.0000  45.0000        50.0000   \n",
      "75%    22.0000   5.0000  30.0000   76.0000  58.0000  50.0000        55.0000   \n",
      "max    27.0000   5.0000  56.0000  100.0000  60.0000  62.0000        69.0000   \n",
      "\n",
      "       eccentricity  \n",
      "count       21.0000  \n",
      "mean        11.3974  \n",
      "std          3.8932  \n",
      "min          3.1615  \n",
      "25%          7.8474  \n",
      "50%         12.9801  \n",
      "75%         13.9532  \n",
      "max         17.6807  \n"
     ]
    }
   ],
   "source": [
    "meta_data = df_calib.groupby('subjID').agg({\n",
    "    'day': 'max',\n",
    "    'gender': 'first',\n",
    "    'race': 'first',  \n",
    "    'handedness': 'first',  \n",
    "    'hemistimulated': 'first',  \n",
    "    'age': 'first',\n",
    "    'weight': 'first',  \n",
    "    'eegsize': 'first',\n",
    "    'PT': 'first',\n",
    "    'StimIntensity': 'first',\n",
    "    'eccentricity': 'first' \n",
    "}).reset_index()\n",
    "print(meta_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check #trials kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daywise_heatmap(df_nocalib, df_nocalib_all5, sub_list, 'trial_count')\n",
    "daywise_heatmap(df_calib, df_calib_all5, sub_list, 'trial_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daywise_trend(df_calib, df_calib_all5, df_nocalib, df_nocalib_all5, sub_list, 'ierr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subject and block eliminations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed subjects: [8, 11, 13, 16, 18]\n",
      "Removed blocks df1:\n",
      "    subjID  day  rnum\n",
      "0        5    1    10\n",
      "1        5    3     4\n",
      "2        5    3     8\n",
      "3        7    2     2\n",
      "4       12    2     8\n",
      "5       12    2     9\n",
      "6       12    2    10\n",
      "7       12    3     6\n",
      "8       12    3     8\n",
      "9       12    3     9\n",
      "10      12    3    10\n",
      "11      15    5     1\n",
      "12      17    2     4\n",
      "13      17    2     6\n",
      "14      17    2     7\n",
      "15      17    2     8\n",
      "16      17    3     5\n",
      "17      22    1     1\n",
      "18      22    1     7\n",
      "19      22    4     4\n",
      "20      22    4     5\n",
      "21      25    1     8\n",
      "22      25    1     9\n",
      "23      25    3     5\n",
      "24      26    3     5\n",
      "25      26    3     7\n",
      "26      26    3    10\n",
      "27      27    1     1\n"
     ]
    }
   ],
   "source": [
    "subs_to_remove = [8, 11, 13, 16, 18]\n",
    "df_calib_filt, df_calib_all5_filt, df_nocalib_filt, df_nocalib_all5_filt = elim_subs_blocks(df_calib, df_calib_all5, df_nocalib, df_nocalib_all5, subs_to_remove)\n",
    "sub_list_filt = [ss for ss in sub_list if ss not in subs_to_remove]\n",
    "sub_list_all5_filt = [ss for ss in sub_list_all5 if ss not in subs_to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_calib = []\n",
    "for sub in sub_list_filt:\n",
    "    tdf_calib = df_calib_filt[df_calib_filt['subjID'] == sub]\n",
    "\n",
    "    subj_data = {\n",
    "        ('NoTMS', 'pro', 'block'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 0) & (tdf_calib['ispro'] == 1)]['rnum'].nunique(),\n",
    "        ('NoTMS', 'pro', 'trial'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 0) & (tdf_calib['ispro'] == 1)]['tnum'].count(),\n",
    "        ('NoTMS', 'anti', 'block'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 0) & (tdf_calib['ispro'] == 0)]['rnum'].nunique(),\n",
    "        ('NoTMS', 'anti', 'trial'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 0) & (tdf_calib['ispro'] == 0)]['tnum'].count(),\n",
    "        ('MidTMS', 'pro', 'block'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 1) & (tdf_calib['ispro'] == 1)]['rnum'].nunique(),\n",
    "        ('MidTMS', 'pro', 'trial'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 1) & (tdf_calib['ispro'] == 1)]['tnum'].count(),\n",
    "        ('MidTMS', 'anti', 'block'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 1) & (tdf_calib['ispro'] == 0)]['rnum'].nunique(),\n",
    "        ('MidTMS', 'anti', 'trial'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 1) & (tdf_calib['ispro'] == 0)]['tnum'].count(),\n",
    "        ('EarlyTMS', 'pro', 'block'): tdf_calib[tdf_calib['day'] == 4]['rnum'].nunique(),\n",
    "        ('EarlyTMS', 'pro', 'trial'): tdf_calib[tdf_calib['day'] == 4]['tnum'].count(),\n",
    "        ('MidTMS dangit', 'pro', 'block'): tdf_calib[tdf_calib['day'] == 5]['rnum'].nunique(),\n",
    "        ('MidTMS dangit', 'pro', 'trial'): tdf_calib[tdf_calib['day'] == 5]['tnum'].count(),\n",
    "    }\n",
    "\n",
    "    data_calib.append(subj_data)\n",
    "count_summary_calib = pd.DataFrame(data_calib, index=sub_list_filt)\n",
    "count_summary_calib.columns = pd.MultiIndex.from_tuples(count_summary_calib.columns)\n",
    "count_summary_calib.index.name = 'subjID'\n",
    "\n",
    "data_nocalib = []\n",
    "for sub in sub_list_filt:\n",
    "    tdf_nocalib = df_nocalib_filt[df_nocalib_filt['subjID'] == sub]\n",
    "    subj_data = {\n",
    "        ('NoTMS', 'pro', 'block'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 0) & (tdf_nocalib['ispro'] == 1)]['rnum'].nunique(),\n",
    "        ('NoTMS', 'pro', 'trial'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 0) & (tdf_nocalib['ispro'] == 1)]['tnum'].count(),\n",
    "        ('NoTMS', 'anti', 'block'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 0) & (tdf_nocalib['ispro'] == 0)]['rnum'].nunique(),\n",
    "        ('NoTMS', 'anti', 'trial'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 0) & (tdf_nocalib['ispro'] == 0)]['tnum'].count(),\n",
    "        ('MidTMS', 'pro', 'block'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 1) & (tdf_nocalib['ispro'] == 1)]['rnum'].nunique(),\n",
    "        ('MidTMS', 'pro', 'trial'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 1) & (tdf_nocalib['ispro'] == 1)]['tnum'].count(),\n",
    "        ('MidTMS', 'anti', 'block'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 1) & (tdf_nocalib['ispro'] == 0)]['rnum'].nunique(),\n",
    "        ('MidTMS', 'anti', 'trial'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 1) & (tdf_nocalib['ispro'] == 0)]['tnum'].count(),\n",
    "        ('EarlyTMS', 'pro', 'block'): tdf_nocalib[tdf_nocalib['day'] == 4]['rnum'].nunique(),\n",
    "        ('EarlyTMS', 'pro', 'trial'): tdf_nocalib[tdf_nocalib['day'] == 4]['tnum'].count(),\n",
    "        ('MidTMS dangit', 'pro', 'block'): tdf_nocalib[tdf_nocalib['day'] == 5]['rnum'].nunique(),\n",
    "        ('MidTMS dangit', 'pro', 'trial'): tdf_nocalib[tdf_nocalib['day'] == 5]['tnum'].count(),\n",
    "    }\n",
    "    data_nocalib.append(subj_data)\n",
    "count_summary_nocalib = pd.DataFrame(data_nocalib, index=sub_list_filt)\n",
    "count_summary_nocalib.columns = pd.MultiIndex.from_tuples(count_summary_nocalib.columns)\n",
    "count_summary_nocalib.index.name = 'subjID'\n",
    "\n",
    "def reshape_for_heatmap(df, count_type):\n",
    "    df_reshaped = df.xs(count_type, level=2, axis=1)\n",
    "    df_reshaped = df_reshaped.stack([0, 1]).reset_index()\n",
    "    df_reshaped.columns = ['subjID', 'Condition', 'Type', count_type]\n",
    "    return df_reshaped\n",
    "\n",
    "data_calib_block = reshape_for_heatmap(count_summary_calib, 'block')\n",
    "data_calib_trial = reshape_for_heatmap(count_summary_calib, 'trial')\n",
    "data_nocalib_block = reshape_for_heatmap(count_summary_nocalib, 'block')\n",
    "data_nocalib_trial = reshape_for_heatmap(count_summary_nocalib, 'trial')\n",
    "\n",
    "data_calib = pd.merge(data_calib_block, data_calib_trial, on=['subjID', 'Condition', 'Type'])\n",
    "data_nocalib = pd.merge(data_nocalib_block, data_nocalib_trial, on=['subjID', 'Condition', 'Type'])\n",
    "\n",
    "desired_order = [\n",
    "    ('NoTMS', 'pro'),\n",
    "    ('NoTMS', 'anti'),\n",
    "    ('MidTMS', 'pro'),\n",
    "    ('MidTMS', 'anti'),\n",
    "    ('EarlyTMS', 'pro'),\n",
    "    ('MidTMS dangit', 'pro'),\n",
    "]\n",
    "\n",
    "p_calib_block = data_calib.pivot_table(index='subjID', columns=['Condition', 'Type'], values='block')\n",
    "p_calib_block = p_calib_block.reindex(desired_order, axis=1)\n",
    "p_calib_trial = data_calib.pivot_table(index='subjID', columns=['Condition', 'Type'], values='trial')\n",
    "p_calib_trial = p_calib_trial.reindex(desired_order, axis=1)\n",
    "p_nocalib_block = data_nocalib.pivot_table(index='subjID', columns=['Condition', 'Type'], values='block')\n",
    "p_nocalib_block = p_nocalib_block.reindex(desired_order, axis=1)\n",
    "p_nocalib_trial = data_nocalib.pivot_table(index='subjID', columns=['Condition', 'Type'], values='trial')\n",
    "p_nocalib_trial = p_nocalib_trial.reindex(desired_order, axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 25))\n",
    "\n",
    "sns.heatmap(p_calib_block, cmap='Blues', annot=True, fmt='g', ax=axs[1, 0])\n",
    "axs[1, 0].set_title('Calib - Block Count')\n",
    "axs[1, 0].set_xlabel('')\n",
    "axs[1, 0].set_ylabel('Subject ID')\n",
    "\n",
    "sns.heatmap(p_calib_trial, cmap='Greens', annot=True, fmt='g', ax=axs[1, 1])\n",
    "axs[1, 1].set_title('Calib - Trial Count')\n",
    "axs[1, 1].set_xlabel('')\n",
    "axs[1, 1].set_ylabel('Subject ID')\n",
    "\n",
    "sns.heatmap(p_nocalib_block, cmap='Blues', annot=True, fmt='g', ax=axs[0, 0])\n",
    "axs[0, 0].set_title('Nocalib - Block Count')\n",
    "axs[0, 0].set_xlabel('')\n",
    "axs[0, 0].set_ylabel('Subject ID')\n",
    "\n",
    "sns.heatmap(p_nocalib_trial, cmap='Greens', annot=True, fmt='g', ax=axs[0, 1])\n",
    "axs[0, 1].set_title('Nocalib - Trial Count')\n",
    "axs[0, 1].set_xlabel('')\n",
    "axs[0, 1].set_ylabel('Subject ID')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_calib = []\n",
    "for sub in sub_list_filt:\n",
    "    tdf_calib = df_calib_filt[df_calib_filt['subjID'] == sub]\n",
    "\n",
    "    subj_data = {\n",
    "        ('NoTMS', 'pro', 'ierr'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 0) & (tdf_calib['ispro'] == 1)]['ierr'].mean(),\n",
    "        ('NoTMS', 'pro', 'isacc_rt'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 0) & (tdf_calib['ispro'] == 1)]['isacc_rt'].mean(),\n",
    "        ('NoTMS', 'anti', 'ierr'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 0) & (tdf_calib['ispro'] == 0)]['ierr'].mean(),\n",
    "        ('NoTMS', 'anti', 'isacc_rt'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 0) & (tdf_calib['ispro'] == 0)]['isacc_rt'].mean(),\n",
    "        ('MidTMS', 'pro', 'ierr'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 1) & (tdf_calib['ispro'] == 1)]['ierr'].mean(),\n",
    "        ('MidTMS', 'pro', 'isacc_rt'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 1) & (tdf_calib['ispro'] == 1)]['isacc_rt'].mean(),\n",
    "        ('MidTMS', 'anti', 'ierr'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 1) & (tdf_calib['ispro'] == 0)]['ierr'].mean(),\n",
    "        ('MidTMS', 'anti', 'isacc_rt'): tdf_calib[(tdf_calib['day'] < 4) & (tdf_calib['istms'] == 1) & (tdf_calib['ispro'] == 0)]['isacc_rt'].mean(),\n",
    "        ('EarlyTMS', 'pro', 'ierr'): tdf_calib[tdf_calib['day'] == 4]['ierr'].mean(),\n",
    "        ('EarlyTMS', 'pro', 'isacc_rt'): tdf_calib[tdf_calib['day'] == 4]['isacc_rt'].mean(),\n",
    "        ('MidTMS dangit', 'pro', 'ierr'): tdf_calib[tdf_calib['day'] == 5]['ierr'].mean(),\n",
    "        ('MidTMS dangit', 'pro', 'isacc_rt'): tdf_calib[tdf_calib['day'] == 5]['isacc_rt'].mean(),\n",
    "    }\n",
    "\n",
    "    data_calib.append(subj_data)\n",
    "count_summary_calib = pd.DataFrame(data_calib, index=sub_list_filt)\n",
    "count_summary_calib.columns = pd.MultiIndex.from_tuples(count_summary_calib.columns)\n",
    "count_summary_calib.index.name = 'subjID'\n",
    "\n",
    "\n",
    "data_nocalib = []\n",
    "for sub in sub_list_filt:\n",
    "    tdf_nocalib = df_nocalib_filt[df_nocalib_filt['subjID'] == sub]\n",
    "    subj_data = {\n",
    "        ('NoTMS', 'pro', 'ierr'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 0) & (tdf_nocalib['ispro'] == 1)]['ierr'].mean(),\n",
    "        ('NoTMS', 'pro', 'isacc_rt'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 0) & (tdf_nocalib['ispro'] == 1)]['isacc_rt'].mean(),\n",
    "        ('NoTMS', 'anti', 'ierr'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 0) & (tdf_nocalib['ispro'] == 0)]['ierr'].mean(),\n",
    "        ('NoTMS', 'anti', 'isacc_rt'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 0) & (tdf_nocalib['ispro'] == 0)]['isacc_rt'].mean(),\n",
    "        ('MidTMS', 'pro', 'ierr'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 1) & (tdf_nocalib['ispro'] == 1)]['ierr'].mean(),\n",
    "        ('MidTMS', 'pro', 'isacc_rt'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 1) & (tdf_nocalib['ispro'] == 1)]['isacc_rt'].mean(),\n",
    "        ('MidTMS', 'anti', 'ierr'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 1) & (tdf_nocalib['ispro'] == 0)]['ierr'].mean(),\n",
    "        ('MidTMS', 'anti', 'isacc_rt'): tdf_nocalib[(tdf_nocalib['day'] < 4) & (tdf_nocalib['istms'] == 1) & (tdf_nocalib['ispro'] == 0)]['isacc_rt'].mean(),\n",
    "        ('EarlyTMS', 'pro', 'ierr'): tdf_nocalib[tdf_nocalib['day'] == 4]['ierr'].mean(),\n",
    "        ('EarlyTMS', 'pro', 'isacc_rt'): tdf_nocalib[tdf_nocalib['day'] == 4]['isacc_rt'].mean(),\n",
    "        ('MidTMS dangit', 'pro', 'ierr'): tdf_nocalib[tdf_nocalib['day'] == 5]['ierr'].mean(),\n",
    "        ('MidTMS dangit', 'pro', 'isacc_rt'): tdf_nocalib[tdf_nocalib['day'] == 5]['isacc_rt'].mean(),\n",
    "    }\n",
    "    data_nocalib.append(subj_data)\n",
    "count_summary_nocalib = pd.DataFrame(data_nocalib, index=sub_list_filt)\n",
    "count_summary_nocalib.columns = pd.MultiIndex.from_tuples(count_summary_nocalib.columns)\n",
    "count_summary_nocalib.index.name = 'subjID'\n",
    "\n",
    "def reshape_for_heatmap(df, count_type):\n",
    "    df_reshaped = df.xs(count_type, level=2, axis=1)\n",
    "    df_reshaped = df_reshaped.stack([0, 1]).reset_index()\n",
    "    df_reshaped.columns = ['subjID', 'Condition', 'Type', count_type]\n",
    "    return df_reshaped\n",
    "\n",
    "data_calib_block = reshape_for_heatmap(count_summary_calib, 'ierr')\n",
    "data_calib_trial = reshape_for_heatmap(count_summary_calib, 'isacc_rt')\n",
    "data_nocalib_block = reshape_for_heatmap(count_summary_nocalib, 'ierr')\n",
    "data_nocalib_trial = reshape_for_heatmap(count_summary_nocalib, 'isacc_rt')\n",
    "\n",
    "data_calib = pd.merge(data_calib_block, data_calib_trial, on=['subjID', 'Condition', 'Type'])\n",
    "data_nocalib = pd.merge(data_nocalib_block, data_nocalib_trial, on=['subjID', 'Condition', 'Type'])\n",
    "\n",
    "desired_order = [\n",
    "    ('NoTMS', 'pro'),\n",
    "    ('NoTMS', 'anti'),\n",
    "    ('MidTMS', 'pro'),\n",
    "    ('MidTMS', 'anti'),\n",
    "    ('EarlyTMS', 'pro'),\n",
    "    ('MidTMS dangit', 'pro'),\n",
    "]\n",
    "\n",
    "p_calib_block = data_calib.pivot_table(index='subjID', columns=['Condition', 'Type'], values='ierr')\n",
    "p_calib_block = p_calib_block.reindex(desired_order, axis=1)\n",
    "p_calib_trial = data_calib.pivot_table(index='subjID', columns=['Condition', 'Type'], values='isacc_rt')\n",
    "p_calib_trial = p_calib_trial.reindex(desired_order, axis=1)\n",
    "p_nocalib_block = data_nocalib.pivot_table(index='subjID', columns=['Condition', 'Type'], values='ierr')\n",
    "p_nocalib_block = p_nocalib_block.reindex(desired_order, axis=1)\n",
    "p_nocalib_trial = data_nocalib.pivot_table(index='subjID', columns=['Condition', 'Type'], values='isacc_rt')\n",
    "p_nocalib_trial = p_nocalib_trial.reindex(desired_order, axis=1)\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(15, 25))\n",
    "\n",
    "sns.heatmap(p_calib_block, cmap='Blues', annot=True, fmt='.2f', ax=axs[1, 0])\n",
    "axs[1, 0].set_title('Calib - isacc err')\n",
    "axs[1, 0].set_xlabel('')\n",
    "axs[1, 0].set_ylabel('Subject ID')\n",
    "\n",
    "sns.heatmap(p_calib_trial, cmap='Greens', annot=True, fmt='.2f', ax=axs[1, 1])\n",
    "axs[1, 1].set_title('Calib - isacc rt')\n",
    "axs[1, 1].set_xlabel('')\n",
    "axs[1, 1].set_ylabel('Subject ID')\n",
    "\n",
    "sns.heatmap(p_nocalib_block, cmap='Blues', annot=True, fmt='.2f', ax=axs[0, 0])\n",
    "axs[0, 0].set_title('Nocalib - fsacc err')\n",
    "axs[0, 0].set_xlabel('')\n",
    "axs[0, 0].set_ylabel('Subject ID')\n",
    "\n",
    "sns.heatmap(p_nocalib_trial, cmap='Greens', annot=True, fmt='.2f', ax=axs[0, 1])\n",
    "axs[0, 1].set_title('Nocalib - fsacc rt')\n",
    "axs[0, 1].set_xlabel('')\n",
    "axs[0, 1].set_ylabel('Subject ID')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daywise_trend(df_calib_filt, df_calib_all5_filt, df_nocalib_filt, df_nocalib_all5_filt, sub_list_filt, 'ierr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daywise_trend_dual_metric(df_calib_filt, df_calib_all5_filt, df_nocalib_filt, df_nocalib_all5_filt, sub_list_filt, ['ierr', 'isacc_rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_sum, err_sum_all5, err_sum_all5_analysis = plot_error_metric(df_calib_filt, df_calib_all5_filt, sub_list_filt, sub_list_all5_filt, 'ierr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs non-parametric Friedman followed by post-hoc Wilcoxon\n",
    "def compute_stats(summary_df, condition, aspect):\n",
    "    if condition == 'time':\n",
    "        summary_df = summary_df.groupby(['subjID', 'time']).agg({\n",
    "            'Condition': 'first',\n",
    "            'mean': 'mean',\n",
    "            'se': 'mean'\n",
    "        })\n",
    "    \n",
    "    friedman_data = [group[aspect].values for _, group in summary_df.groupby(condition)]\n",
    "    friedman_stat, friedman_p = stats.friedmanchisquare(*friedman_data)\n",
    "    print(f'Statistical analsysis for: {condition}: {aspect}')\n",
    "    print(f'Friedman Test Statistic: {round(friedman_stat, 3)}, P-value: {round(friedman_p, 3)}')\n",
    "\n",
    "    if friedman_p < 0.05:\n",
    "        if condition == 'Condition':\n",
    "            comparison_pairs = [\n",
    "                ('mid inVF', 'mid outVF'),\n",
    "                ('early inVF', 'early outVF'),\n",
    "                ('mid dangit inVF', 'mid dangit outVF'),\n",
    "            ]\n",
    "        elif condition == 'time':\n",
    "            comparison_pairs = [\n",
    "                ('notms', 'mid'),\n",
    "                ('notms', 'early'),\n",
    "                ('notms', 'mid dangit')\n",
    "            ]\n",
    "        num_tests = len(comparison_pairs)+1 # +1 for Friedman test\n",
    "        alpha_adjusted = 0.05 / num_tests  \n",
    "        print(f'Corrected alpha value after Bonferroni correction for {num_tests} tests = {round(alpha_adjusted, 4)}')\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for pair in comparison_pairs:\n",
    "            condition1, condition2 = pair\n",
    "            data1 = summary_df[summary_df[condition] == condition1][aspect]\n",
    "            data2 = summary_df[summary_df[condition] == condition2][aspect]\n",
    "            stat, pval = stats.wilcoxon(data1, data2)\n",
    "            pval_adj = pval * num_tests\n",
    "            reject = pval < alpha_adjusted\n",
    "            results.append([condition1, condition2, stat, pval, pval_adj, reject])\n",
    "\n",
    "        results_df = pd.DataFrame(results, columns=['Condition 1', 'Condition 2', 'WRS_stat', 'p-value', 'adj p-value', 'Reject Null'])\n",
    "        print(results_df)\n",
    "          \n",
    "compute_stats(err_sum_all5, 'Condition', 'mean')\n",
    "compute_stats(err_sum_all5, 'Condition', 'se')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performs permutation tests by shuffling at the subject level\n",
    "def compute_diff(x, y, axis):\n",
    "    return np.mean(x, axis) - np.mean(y, axis)\n",
    "\n",
    "def perform_permutation_test(df, time1, VF1, time2, VF2, title_text, ax):\n",
    "    dat1 = df[(df['time'] == time1) & (df['VF'] == VF1)]['mean']\n",
    "    dat2 = df[(df['time'] == time2) & (df['VF'] == VF2)]['mean']\n",
    "\n",
    "    res = stats.permutation_test((dat1, dat2), compute_diff, vectorized=True, permutation_type='samples',\n",
    "                                 n_resamples=1e6, alternative='two-sided', random_state=42)\n",
    "\n",
    "    sns.histplot(res.null_distribution, element='step', fill=False, ax=ax)\n",
    "    ax.axvline(x=res.statistic, color='k', linestyle='--')\n",
    "    # ax.set_xlim([-0.35, 0.35])\n",
    "    # ax.text(-0.25, 1000.2, f'stat={res.statistic:.3f}\\np={res.pvalue:.3f}', fontsize=9, color='black')\n",
    "    ax.set_title(title_text)\n",
    "    return res.pvalue\n",
    "\n",
    "df_analysis = err_sum_all5_analysis\n",
    "\n",
    "pairs_to_test = [\n",
    "    ('early', 1, 'early', 0, 'early in vs out'),\n",
    "    ('mid', 1, 'mid', 0, 'mid in vs out'),\n",
    "    ('mid dangit', 1, 'mid dangit', 0, 'mid dangit in vs out'),\n",
    "    ('early', 1, 'notms', 1, 'notms vs early for inVF'),\n",
    "    ('early', 0, 'notms', 0, 'notms vs early for outVF'),\n",
    "    ('mid', 1, 'notms', 1, 'notms vs mid for inVF'),\n",
    "    ('mid', 1, 'mid dangit', 1, 'mid vs mid dangit for inVF')\n",
    "]\n",
    "\n",
    "n_tests = len(pairs_to_test)\n",
    "n_cols = 2 \n",
    "n_rows = n_tests // n_cols + (n_tests % n_cols > 0)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 5))\n",
    "if n_rows > 1:\n",
    "    axes = axes.flatten()\n",
    "else:\n",
    "    axes = [axes]\n",
    "for i, (time1, VF1, time2, VF2, title_text) in enumerate(pairs_to_test):\n",
    "    perform_permutation_test(df_analysis, time1, VF1, time2, VF2, title_text, axes[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summary(df_all5, metric):\n",
    "    conds_all5_analysis = {\n",
    "        'No TMS inVF': df_all5[(df_all5['istms'] == 0) & (df_all5['instimVF'] == 1) & (df_all5['day'].isin([1, 2, 3]))],\n",
    "        'No TMS outVF': df_all5[(df_all5['istms'] == 0) & (df_all5['instimVF'] == 0) & (df_all5['day'].isin([1, 2, 3]))],\n",
    "        'mid inVF': df_all5[(df_all5['istms'] == 1) & (df_all5['instimVF'] == 1) & (df_all5['day'].isin([1, 2, 3]))],\n",
    "        'mid outVF': df_all5[(df_all5['istms'] == 1) & (df_all5['instimVF'] == 0) & (df_all5['day'].isin([1, 2, 3]))],\n",
    "        'early inVF': df_all5[(df_all5['istms'] == 1) & (df_all5['instimVF'] == 1) & (df_all5['day'] == 4)],\n",
    "        'early outVF': df_all5[(df_all5['istms'] == 1) & (df_all5['instimVF'] == 0) & (df_all5['day'] == 4)],\n",
    "        'mid dangit inVF': df_all5[(df_all5['istms'] == 1) & (df_all5['instimVF'] == 1) & (df_all5['day'] == 5)],\n",
    "        'mid dangit outVF': df_all5[(df_all5['istms'] == 1) & (df_all5['instimVF'] == 0) & (df_all5['day'] == 5)],\n",
    "    }\n",
    "    \n",
    "    results_all5_analysis = {cond: data.groupby('subjID').apply(calculate_mean_and_se, error_metric=metric) for cond, data in conds_all5_analysis.items()}\n",
    "    combined_all5_analysis = pd.concat(results_all5_analysis, names=['Condition']).reset_index()\n",
    "    combined_all5_analysis['time'] = combined_all5_analysis['Condition'].apply(lambda x: 'notms' if 'No TMS' in x else ('early' if 'early' in x else ('mid dangit' if 'mid dangit' in x else 'mid')))\n",
    "    combined_all5_analysis['VF'] = combined_all5_analysis['Condition'].apply(lambda x: 1 if 'inVF' in x else 0)\n",
    "    return combined_all5_analysis\n",
    "\n",
    "def compute_stats_parametric(df, pairs_to_test):\n",
    "    tvect = np.zeros((len(pairs_to_test),))\n",
    "    for i, (time1, VF1, time2, VF2, _) in enumerate(pairs_to_test):\n",
    "        data1 = df[(df['time'] == time1) & (df['VF'] == VF1)]['mean']\n",
    "        data2 = df[(df['time'] == time2) & (df['VF'] == VF2)]['mean']\n",
    "        tstat, _ = stats.ttest_rel(data1, data2, nan_policy = 'omit', alternative='two-sided')\n",
    "        tvect[i] = tstat\n",
    "    return tvect\n",
    "    \n",
    "\n",
    "start = time.time()\n",
    "iter_count = 20000\n",
    "pairs_to_test = [\n",
    "    ('early', 1, 'early', 0, 'early in vs out'),\n",
    "    ('mid', 1, 'mid', 0, 'mid in vs out'),\n",
    "    ('mid dangit', 1, 'mid dangit', 0, 'mid dangit in vs out'),\n",
    "    ('early', 1, 'notms', 1, 'notms vs early for inVF'),\n",
    "    ('early', 0, 'notms', 0, 'notms vs early for outVF'),\n",
    "    ('mid', 1, 'notms', 1, 'notms vs mid for inVF'),\n",
    "    ('mid', 1, 'mid dangit', 1, 'mid vs mid dangit for inVF')\n",
    "]\n",
    "n_tests = len(pairs_to_test)\n",
    "n_cols = 2 \n",
    "n_rows = n_tests // n_cols + (n_tests % n_cols > 0)\n",
    "\n",
    "tstat_compiled = np.zeros((iter_count, len(pairs_to_test)))\n",
    "    \n",
    "for ii in range(iter_count):\n",
    "    df_temp = df_calib_all5_filt.copy()\n",
    "    istms_shuffle = np.random.permutation(df_temp['istms'])\n",
    "    stimVF_shuffle = np.random.permutation(df_temp['instimVF'])\n",
    "    day_shuffle = np.random.permutation(df_temp['day'])\n",
    "    df_temp['istms'] = istms_shuffle\n",
    "    df_temp['instimVF'] = stimVF_shuffle\n",
    "    df_temp['day'] = day_shuffle\n",
    "    df_analysis = get_summary(df_temp, 'ferr')\n",
    "    tvect_this = compute_stats_parametric(df_analysis, pairs_to_test)\n",
    "    tstat_compiled[ii, :] = tvect_this\n",
    "\n",
    "df_analysis_real = get_summary(df_calib_all5_filt, 'ferr')\n",
    "tstat_real = compute_stats_parametric(df_analysis_real, pairs_to_test)\n",
    "pval_2side = []\n",
    "pval_1side = []\n",
    "for ii in range(n_tests):\n",
    "    if tstat_real[ii] >= 0:\n",
    "        samps_bothside = sum(tstat_compiled[:, ii] >= tstat_real[ii]) + sum(tstat_compiled[:, ii] < -tstat_real[ii])\n",
    "    else:\n",
    "        samps_bothside = sum(tstat_compiled[:, ii] >= -tstat_real[ii]) + sum(tstat_compiled[:, ii] < tstat_real[ii])\n",
    "    samps_oneside = sum(tstat_compiled[:, ii] >= tstat_real[ii])\n",
    "    pval_2side.append(samps_bothside/iter_count)\n",
    "    pval_1side.append(samps_oneside/iter_count)\n",
    "print(f\"Total time taken for running {iter_count} permutations: {round(time.time()-start, 3)} s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'perform_permutation_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m n_rows \u001b[38;5;241m=\u001b[39m n_tests \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_cols \u001b[38;5;241m+\u001b[39m (n_tests \u001b[38;5;241m%\u001b[39m n_cols \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m iter_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m---> 17\u001b[0m tstat_real, tstat_permuted, pval_1side, pval_2side \u001b[38;5;241m=\u001b[39m \u001b[43mperform_permutation_test\u001b[49m(df_calib_all5_filt, \n\u001b[1;32m     18\u001b[0m                                                                               pairs_to_test, metric, iter_count)\n\u001b[1;32m     20\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(n_rows, n_cols, figsize\u001b[38;5;241m=\u001b[39m(n_cols \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m, n_rows \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_rows \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'perform_permutation_test' is not defined"
     ]
    }
   ],
   "source": [
    "metric = 'ierr'\n",
    "\n",
    "pairs_to_test = [\n",
    "    ('notms inVF', 'early inVF', 'notms vs early inVF'),\n",
    "    ('notms inVF', 'mid inVF', 'notms vs mid inVF'),\n",
    "    ('notms outVF', 'early outVF', 'notms vs early outVF'),\n",
    "    ('notms outVF', 'mid outVF', 'notms vs mid outVF'),\n",
    "    ('mid inVF', 'mid outVF', 'mid in vs out'),\n",
    "    ('early inVF', 'early outVF', 'early in vs out'),\n",
    "    ('mid inVF', 'mid outVF', 'mid in vs out'),\n",
    "]\n",
    "n_tests = len(pairs_to_test)\n",
    "n_cols = 2 \n",
    "n_rows = n_tests // n_cols + (n_tests % n_cols > 0)\n",
    "iter_count = 200\n",
    "\n",
    "tstat_real, tstat_permuted, pval_1side, pval_2side = perform_permutation_test(df_calib_all5_filt, \n",
    "                                                                              pairs_to_test, metric, iter_count)\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5, n_rows * 5))\n",
    "if n_rows > 1:\n",
    "    axes = axes.flatten()\n",
    "else:\n",
    "    axes = [axes]\n",
    "for i in range(len(pairs_to_test)):\n",
    "    plot_permutation_result(tstat_permuted, tstat_real, pval_2side, pval_1side, i, pairs_to_test, axes[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(sub_list_filt), 5, figsize=(20, 7 * len(sub_list)))\n",
    "\n",
    "for sub in range(len(sub_list_filt)):\n",
    "    this_sub = sub_list_filt[sub]\n",
    "    for day in range(5):\n",
    "        df_today_pro = df_nocalib_filt[(df_nocalib_filt['subjID'] == this_sub) & (df_nocalib_filt['day'] == day+1) & (df_nocalib_filt['ispro'] == 1)]\n",
    "        df_today_anti = df_nocalib_filt[(df_nocalib_filt['subjID'] == this_sub) & (df_nocalib_filt['day'] == day+1) & (df_nocalib_filt['ispro'] == 0)]\n",
    "        this_tr_num_pro = ((df_today_pro['rnum'] - 1) * 40 + df_today_pro['tnum'])\n",
    "        this_tr_num_anti = ((df_today_anti['rnum'] - 1) * 40 + df_today_anti['tnum'])\n",
    "\n",
    "        axs[sub, day].plot(this_tr_num_pro, df_today_pro['ierr'], 'ko', markersize=2) \n",
    "        axs[sub, day].plot(this_tr_num_anti, df_today_anti['ierr'], 'ro', markersize=2) \n",
    "\n",
    "        if day >= 3:  \n",
    "            df_today = df_nocalib_all5_filt[(df_nocalib_all5_filt['subjID'] == this_sub) & (df_nocalib_all5_filt['day'] == day+1)]\n",
    "            this_tr_num = ((df_today['rnum'] - 1) * 40 + df_today['tnum'])\n",
    "\n",
    "            if day == 3:  \n",
    "                color = 'go' \n",
    "            elif day == 4:  \n",
    "                color = 'bo' \n",
    "\n",
    "            axs[sub, day].plot(this_tr_num, df_today['ierr'], color, markersize=2)\n",
    "        axs[sub, day].set_xlabel('Trial')\n",
    "        axs[sub, day].set_ylabel('MGS Error (dva)')\n",
    "        axs[sub, day].set_ylim([0, 6.5])\n",
    "        axs[sub, day].set_title(f'Sub = {this_sub}, Day = {day + 1}')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    return np.convolve(data, np.ones(window_size)/window_size, mode='valid')\n",
    "\n",
    "mov_window = 7 \n",
    "\n",
    "fig, axs = plt.subplots(len(sub_list_filt), 5, figsize=(20, 7 * len(sub_list_filt)))\n",
    "\n",
    "for sub in range(len(sub_list_filt)):\n",
    "    this_sub = sub_list_filt[sub]\n",
    "    for day in range(5):\n",
    "        is_istms_zero_day = False\n",
    "        if day < 3:\n",
    "            df_today_pro = df_calib_filt[(df_calib_filt['subjID'] == this_sub) & (df_calib_filt['day'] == day+1) & (df_calib_filt['ispro'] == 1)]\n",
    "            df_today_anti = df_calib_filt[(df_calib_filt['subjID'] == this_sub) & (df_calib_filt['day'] == day+1) & (df_calib_filt['ispro'] == 0)]\n",
    "            this_tr_num_pro = ((df_today_pro['rnum'] - 1) * 40 + df_today_pro['tnum'])\n",
    "            this_tr_num_anti = ((df_today_anti['rnum'] - 1) * 40 + df_today_anti['tnum'])\n",
    "\n",
    "            ma_error_pro = moving_average(df_today_pro['ierr'], mov_window)\n",
    "            ma_error_anti = moving_average(df_today_anti['ierr'], mov_window)\n",
    "\n",
    "            adj_tr_num_pro = this_tr_num_pro[:len(ma_error_pro)]\n",
    "            adj_tr_num_anti = this_tr_num_anti[:len(ma_error_anti)]\n",
    "\n",
    "            axs[sub, day].plot(adj_tr_num_pro, ma_error_pro, 'k-', label='Pro')  \n",
    "            axs[sub, day].plot(adj_tr_num_anti, ma_error_anti, 'r-', label='Anti')  \n",
    "\n",
    "            if df_today_pro['istms'].eq(0).any() or df_today_anti['istms'].eq(0).any():\n",
    "                is_istms_zero_day = True\n",
    "\n",
    "            for block_start in np.unique(df_today_pro['rnum']):\n",
    "                axs[sub, day].axvline(x=((block_start - 1) * 40), color='grey', linestyle='--', alpha=0.5)\n",
    "            for block_start in np.unique(df_today_anti['rnum']):\n",
    "                axs[sub, day].axvline(x=((block_start - 1) * 40), color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "        elif day >= 3:\n",
    "            if this_sub in sub_list_all5:\n",
    "                df_today = df_calib_filt[(df_calib_filt['subjID'] == this_sub) & (df_calib_filt['day'] == day+1)]\n",
    "                this_tr_num = ((df_today['rnum'] - 1) * 40 + df_today['tnum'])\n",
    "                ma_error = moving_average(df_today['ierr'], mov_window)\n",
    "                adj_tr_num = this_tr_num[:len(ma_error)]\n",
    "\n",
    "                if day == 3:\n",
    "                    color = 'g-'\n",
    "                elif day == 4:\n",
    "                    color = 'b-'\n",
    "                \n",
    "                axs[sub, day].plot(adj_tr_num, ma_error, color, label='TMS')\n",
    "\n",
    "                for block_start in np.unique(df_today['rnum']):\n",
    "                    axs[sub, day].axvline(x=((block_start - 1) * 40), color='grey', linestyle='--', alpha=0.5)\n",
    "\n",
    "        if is_istms_zero_day:\n",
    "            axs[sub, day].spines['top'].set_color('orange')\n",
    "            axs[sub, day].spines['right'].set_color('orange')\n",
    "            axs[sub, day].spines['left'].set_color('orange')\n",
    "            axs[sub, day].spines['bottom'].set_color('orange')\n",
    "            axs[sub, day].spines['top'].set_linewidth(2)\n",
    "            axs[sub, day].spines['right'].set_linewidth(2)\n",
    "            axs[sub, day].spines['left'].set_linewidth(2)\n",
    "            axs[sub, day].spines['bottom'].set_linewidth(2)\n",
    "\n",
    "        axs[sub, day].set_xlabel('Trial')\n",
    "        axs[sub, day].set_ylabel('MGS Error (dva)')\n",
    "        axs[sub, day].set_ylim([0, 6.5])\n",
    "        axs[sub, day].set_title(f'Sub = {this_sub}, Day = {day + 1}')\n",
    "        axs[sub, day].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pairwise plots for conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.power import TTestPower \n",
    "from statsmodels.stats.power import TTestIndPower \n",
    "df_plot = err_sum_all5_analysis\n",
    "mean_x = df_plot[(df_plot['time']=='mid') & (df_plot['VF']==1)]['mean'] \n",
    "mean_y = df_plot[(df_plot['time']=='notms') & (df_plot['VF']==1)]['mean'] \n",
    "cohens_d = (np.mean(mean_x)- np.mean(mean_y)) / np.sqrt((np.std(mean_x) ** 2 + np.std(mean_y, ) ** 2) / 2.0)\n",
    "\n",
    "# cohens_d = (tdf['mean'] - np.mean(tdf['mean']))/np.std(tdf['mean'])\n",
    "print(cohens_d)\n",
    "\n",
    "alpha = 0.05\n",
    "power = 0.8\n",
    "  \n",
    "# perform power analysis to find sample size  \n",
    "# for given effect \n",
    "obj = TTestPower() \n",
    "n = obj.solve_power(effect_size=cohens_d, alpha=alpha, power=power,  \n",
    "                     alternative='larger') \n",
    "print(n)\n",
    "\n",
    "obj = TTestIndPower() \n",
    "n = obj.solve_power(effect_size=cohens_d, alpha=alpha, power=power,  \n",
    "                     ratio=1, alternative='two-sided') \n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = err_sum_all5_analysis\n",
    "plt.figure(figsize=(20, 10))\n",
    "times = ['notms', 'mid', 'early', 'mid dangit']\n",
    "\n",
    "time_pairs = [\n",
    "    ('notms', 'early'),\n",
    "    ('notms', 'mid'),\n",
    "    ('notms', 'mid dangit'),\n",
    "    ('early', 'mid'),\n",
    "    ('mid', 'mid dangit'),\n",
    " ]\n",
    "\n",
    "# Create figure for the subplots\n",
    "plt.figure(figsize=(8, 10))\n",
    "\n",
    "# Plotting each pair of times\n",
    "for i, (time1, time2) in enumerate(time_pairs, 1):\n",
    "    plt.subplot(3, 2, i)\n",
    "\n",
    "    # Merging the mean values for the two times for each subject and condition\n",
    "    df_time1 = df_plot[df_plot['time'] == time1][['subjID', 'mean', 'VF', 'Condition']]\n",
    "    df_time2 = df_plot[df_plot['time'] == time2][['subjID', 'mean', 'VF', 'Condition']]\n",
    "    df_time1.rename(columns={'mean': f'mean_{time1}'}, inplace=True)\n",
    "    df_time2.rename(columns={'mean': f'mean_{time2}'}, inplace=True)\n",
    "    merged_df = pd.merge(df_time1, df_time2, on=['subjID', 'VF'])#, 'VF', 'Condition'])\n",
    "\n",
    "    sns.scatterplot(data=merged_df, x=f'mean_{time1}', y=f'mean_{time2}', hue='VF', palette='deep')\n",
    "    plt.plot([0, 3], [0, 3], 'k--')\n",
    "    for vf in [0, 1]:\n",
    "        vf_data = merged_df[merged_df['VF'] == vf]\n",
    "        corr, _ = stats.pearsonr(vf_data[f'mean_{time1}'], vf_data[f'mean_{time2}'])\n",
    "        plt.text(0.1, 2.8 - 0.2 * vf, f'VF={vf}: r={corr:.2f}', fontsize=9, color='blue' if vf == 0 else 'red')\n",
    "\n",
    "    plt.title(f'{time1} vs {time2}')\n",
    "    plt.xlim([0, 3])\n",
    "    plt.ylim([0, 3])\n",
    "    plt.xlabel(f'{time1}')\n",
    "    plt.ylabel(f'{time2}')\n",
    "    plt.legend(title='VF', loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "for i, time in enumerate(times, 1):\n",
    "    plt.subplot(2, 2, i)\n",
    "\n",
    "    df_inVF = df_plot[(df_plot['time'] == time) & (df_plot['VF'] == 1)][['subjID', 'mean']]\n",
    "    df_outVF = df_plot[(df_plot['time'] == time) & (df_plot['VF'] == 0)][['subjID', 'mean']]\n",
    "    df_inVF.rename(columns={'mean': 'mean_inVF'}, inplace=True)\n",
    "    df_outVF.rename(columns={'mean': 'mean_outVF'}, inplace=True)\n",
    "    merged_df = pd.merge(df_inVF, df_outVF, on='subjID')\n",
    "\n",
    "    sns.scatterplot(data=merged_df, x='mean_inVF', y='mean_outVF')\n",
    "    plt.plot([0, 3], [0, 3], 'k--')\n",
    "    plt.xlim([0, 3])\n",
    "    plt.ylim([0, 3])\n",
    "    corr, _ = stats.pearsonr(merged_df['mean_inVF'], merged_df['mean_outVF'])\n",
    "    plt.text(0.1, 2.8, f'r={corr:.2f}', fontsize=9, color='black')\n",
    "    plt.title(f'Time: {time}')\n",
    "    plt.xlabel('Error inVF')\n",
    "    plt.ylabel('Error outVF')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Did subjects use semantic knowledge of target location?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = np.unique(df['subjID'].values)\n",
    "#sub_list = [1, 3]\n",
    "fig, axs = plt.subplots(len(sub_list), 3, figsize = (20, 5*len(sub_list)))\n",
    "x = [0.5, 0.7, 0.9, 1.3, 1.5, 1.7, 2.1, 2.3, 2.5, 2.9, 3.1, 3.3]\n",
    "bar_width = 0.2\n",
    "labels = ['actual\\nerror', 'semantic\\nerror', 'max\\nerror', 'actual\\nerror', 'semantic\\nerror', 'max\\nerror',\n",
    "          'actual\\nerror', 'semantic\\nerror', 'max\\nerror', 'actual\\nerror', 'semantic\\nerror', 'max\\nerror']\n",
    "\n",
    "legend_handles = []\n",
    "for sub in range(len(sub_list)):\n",
    "    this_sub = sub_list[sub]\n",
    "    for day in range(3):\n",
    "        df_pro_instimVF = df[(df['subjID'] == this_sub) & (df['day'] == day+1) & (df['ispro'] == 1) & (df['instimVF'] == 1)]\n",
    "        df_pro_outstimVF = df[(df['subjID'] == this_sub) & (df['day'] == day+1) & (df['ispro'] == 1) & (df['instimVF'] == 0)]\n",
    "        df_anti_instimVF = df[(df['subjID'] == this_sub) & (df['day'] == day+1) & (df['ispro'] == 0) & (df['instimVF'] == 1)]\n",
    "        df_anti_outstimVF = df[(df['subjID'] == this_sub) & (df['day'] == day+1) & (df['ispro'] == 0) & (df['instimVF'] == 0)]\n",
    "        \n",
    "        tr_num_pro_instimVF = ((df_pro_instimVF['rnum'] - 1) * 40 + df_pro_instimVF['tnum'])\n",
    "        tr_num_pro_outstimVF = ((df_pro_outstimVF['rnum'] - 1) * 40 + df_pro_outstimVF['tnum'])\n",
    "        tr_num_anti_instimVF = ((df_anti_instimVF['rnum'] - 1) * 40 + df_anti_instimVF['tnum'])\n",
    "        tr_num_anti_outstimVF = ((df_anti_outstimVF['rnum'] - 1) * 40 + df_anti_outstimVF['tnum'])\n",
    "        \n",
    "        Xpi_sem = np.median(df_pro_instimVF['TarX'])\n",
    "        Ypi_sem = np.median(df_pro_instimVF['TarY'])\n",
    "        Xpo_sem = np.median(df_pro_outstimVF['TarX'])\n",
    "        Ypo_sem = np.median(df_pro_outstimVF['TarY'])\n",
    "        Xai_sem = np.median(df_anti_instimVF['TarX'])\n",
    "        Yai_sem = np.median(df_anti_instimVF['TarY'])\n",
    "        Xao_sem = np.median(df_anti_outstimVF['TarX'])\n",
    "        Yao_sem = np.median(df_anti_outstimVF['TarY'])\n",
    "\n",
    "        errpi_sem = np.sqrt((df_pro_instimVF['isaccX']-Xpi_sem)**2+(df_pro_instimVF['isaccY']-Ypi_sem)**2)\n",
    "        errpo_sem = np.sqrt((df_pro_outstimVF['isaccX']-Xpo_sem)**2+(df_pro_outstimVF['isaccY']-Ypo_sem)**2)\n",
    "        errai_sem = np.sqrt((df_anti_instimVF['isaccX']-Xai_sem)**2+(df_anti_instimVF['isaccY']-Yai_sem)**2)\n",
    "        errao_sem = np.sqrt((df_anti_outstimVF['isaccX']-Xao_sem)**2+(df_anti_outstimVF['isaccY']-Yao_sem)**2)\n",
    "        \n",
    "        tarpi_sem = np.sqrt((df_pro_instimVF['TarX']-Xpi_sem)**2+(df_pro_instimVF['TarY']-Ypi_sem)**2)\n",
    "        tarpo_sem = np.sqrt((df_pro_outstimVF['TarX']-Xpo_sem)**2+(df_pro_outstimVF['TarY']-Ypo_sem)**2)\n",
    "        tarai_sem = np.sqrt((df_anti_instimVF['TarX']-Xai_sem)**2+(df_anti_instimVF['TarY']-Yai_sem)**2)\n",
    "        tarao_sem = np.sqrt((df_anti_outstimVF['TarX']-Xao_sem)**2+(df_anti_outstimVF['TarY']-Yao_sem)**2)\n",
    "        \n",
    "\n",
    "        errpi = df_pro_instimVF['ierr']\n",
    "        errpo = df_pro_outstimVF['ierr']\n",
    "        errai = df_anti_instimVF['ierr']\n",
    "        errao = df_anti_outstimVF['ierr']\n",
    "        \n",
    "        \n",
    "        pi_mean = [np.mean(errpi), np.mean(errpi_sem), np.mean(tarpi_sem)]\n",
    "        po_mean = [np.mean(errpo), np.mean(errpo_sem), np.mean(tarpo_sem)]\n",
    "        ai_mean = [np.mean(errai), np.mean(errai_sem), np.mean(tarai_sem)]\n",
    "        ao_mean = [np.mean(errao), np.mean(errao_sem), np.mean(tarao_sem)]\n",
    "        pi_var = [sem(errpi), sem(errpi_sem), sem(tarpi_sem)]\n",
    "        po_var = [sem(errpo), sem(errpo_sem), sem(tarpo_sem)]\n",
    "        ai_var = [sem(errai), sem(errai_sem), sem(tarai_sem)]\n",
    "        ao_var = [sem(errao), sem(errao_sem), sem(tarao_sem)]\n",
    "        \n",
    "        bar1 = axs[sub, day].bar(x[:3], pi_mean, bar_width, label='pro instimVF', yerr=pi_var, capsize=5)\n",
    "        bar2 = axs[sub, day].bar(x[3:6], po_mean, bar_width, label='pro outstimVF', yerr=po_var, capsize=5)\n",
    "        bar3 = axs[sub, day].bar(x[6:9], ai_mean, bar_width, label='anti instimVF', yerr=ai_var, capsize=5)\n",
    "        bar4 = axs[sub, day].bar(x[9:], ao_mean, bar_width, label='anti outstimVF', yerr=ao_var, capsize=5)\n",
    "        legend_handles.extend([bar1, bar2, bar3, bar4])\n",
    "        axs[sub, day].set_ylabel('isacc_err')\n",
    "        axs[sub, day].set_title('Sub = ' + str(this_sub) + ', Day = ' + str(day))\n",
    "        axs[sub, day].set_xticks(x)\n",
    "        axs[sub, day].set_xticklabels(labels, rotation = 45)\n",
    "        #axs[sub, day].legend()\n",
    "fig.legend(legend_handles, ['pro instimVF', 'pro outstimVF', 'anti instimVF', 'anti outstimVF'],\n",
    "           loc='upper right', bbox_to_anchor=(1.0, 1.0))\n",
    "# for ax in axs[-1]:\n",
    "#     ax.set_xticklabels(labels, rotation=45, ha='right')  # Adjust rotation angle as needed\n",
    "\n",
    "plt.subplots_adjust(right=0.85)  \n",
    "\n",
    "#fig.suptitle('Learning curve')\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1.0])  # Adjust the rect parameter as needed\n",
    "plt.savefig(save_folder + 'semantic_strategy.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_list = np.unique(df['subjID'].values)\n",
    "#sub_list = [1, 3]\n",
    "fig, axs = plt.subplots(len(sub_list), 1, figsize = (20, 5*len(sub_list)))\n",
    "x = [0.5, 0.7, 0.9, 1.3, 1.5, 1.7, 2.1, 2.3, 2.5, 2.9, 3.1, 3.3]\n",
    "bar_width = 0.2\n",
    "labels = ['actual\\nerror', 'semantic\\nerror', 'centroid\\nerror', 'actual\\nerror', 'semantic\\nerror', 'centroid\\nerror',\n",
    "          'actual\\nerror', 'semantic\\nerror', 'centroid\\nerror', 'actual\\nerror', 'semantic\\nerror', 'centroid\\nerror']\n",
    "\n",
    "legend_handles = []\n",
    "for sub in range(len(sub_list)):\n",
    "    this_sub = sub_list[sub]\n",
    "    #for day in range(3):\n",
    "    df_pro_instimVF = df[(df['subjID'] == this_sub) & (df['ispro'] == 1) & (df['instimVF'] == 1)]\n",
    "    df_pro_outstimVF = df[(df['subjID'] == this_sub)  & (df['ispro'] == 1) & (df['instimVF'] == 0)]\n",
    "    df_anti_instimVF = df[(df['subjID'] == this_sub) & (df['ispro'] == 0) & (df['instimVF'] == 1)]\n",
    "    df_anti_outstimVF = df[(df['subjID'] == this_sub) & (df['ispro'] == 0) & (df['instimVF'] == 0)]\n",
    "    \n",
    "    tr_num_pro_instimVF = ((df_pro_instimVF['rnum'] - 1) * 40 + df_pro_instimVF['tnum'])\n",
    "    tr_num_pro_outstimVF = ((df_pro_outstimVF['rnum'] - 1) * 40 + df_pro_outstimVF['tnum'])\n",
    "    tr_num_anti_instimVF = ((df_anti_instimVF['rnum'] - 1) * 40 + df_anti_instimVF['tnum'])\n",
    "    tr_num_anti_outstimVF = ((df_anti_outstimVF['rnum'] - 1) * 40 + df_anti_outstimVF['tnum'])\n",
    "    \n",
    "    Xpi_sem = np.median(df_pro_instimVF['TarX'])\n",
    "    Ypi_sem = np.median(df_pro_instimVF['TarY'])\n",
    "    Xpo_sem = np.median(df_pro_outstimVF['TarX'])\n",
    "    Ypo_sem = np.median(df_pro_outstimVF['TarY'])\n",
    "    Xai_sem = np.median(df_anti_instimVF['TarX'])\n",
    "    Yai_sem = np.median(df_anti_instimVF['TarY'])\n",
    "    Xao_sem = np.median(df_anti_outstimVF['TarX'])\n",
    "    Yao_sem = np.median(df_anti_outstimVF['TarY'])\n",
    "\n",
    "    errpi_sem = np.sqrt((df_pro_instimVF['isaccX']-Xpi_sem)**2+(df_pro_instimVF['isaccY']-Ypi_sem)**2)\n",
    "    errpo_sem = np.sqrt((df_pro_outstimVF['isaccX']-Xpo_sem)**2+(df_pro_outstimVF['isaccY']-Ypo_sem)**2)\n",
    "    errai_sem = np.sqrt((df_anti_instimVF['isaccX']-Xai_sem)**2+(df_anti_instimVF['isaccY']-Yai_sem)**2)\n",
    "    errao_sem = np.sqrt((df_anti_outstimVF['isaccX']-Xao_sem)**2+(df_anti_outstimVF['isaccY']-Yao_sem)**2)\n",
    "    \n",
    "    tarpi_sem = np.sqrt((df_pro_instimVF['TarX']-Xpi_sem)**2+(df_pro_instimVF['TarY']-Ypi_sem)**2)\n",
    "    tarpo_sem = np.sqrt((df_pro_outstimVF['TarX']-Xpo_sem)**2+(df_pro_outstimVF['TarY']-Ypo_sem)**2)\n",
    "    tarai_sem = np.sqrt((df_anti_instimVF['TarX']-Xai_sem)**2+(df_anti_instimVF['TarY']-Yai_sem)**2)\n",
    "    tarao_sem = np.sqrt((df_anti_outstimVF['TarX']-Xao_sem)**2+(df_anti_outstimVF['TarY']-Yao_sem)**2)\n",
    "    \n",
    "\n",
    "    errpi = df_pro_instimVF['ierr']\n",
    "    errpo = df_pro_outstimVF['ierr']\n",
    "    errai = df_anti_instimVF['ierr']\n",
    "    errao = df_anti_outstimVF['ierr']\n",
    "    \n",
    "    \n",
    "    pi_mean = [np.mean(errpi), np.mean(errpi_sem), np.mean(tarpi_sem)]\n",
    "    po_mean = [np.mean(errpo), np.mean(errpo_sem), np.mean(tarpo_sem)]\n",
    "    ai_mean = [np.mean(errai), np.mean(errai_sem), np.mean(tarai_sem)]\n",
    "    ao_mean = [np.mean(errao), np.mean(errao_sem), np.mean(tarao_sem)]\n",
    "    pi_var = [sem(errpi), sem(errpi_sem), sem(tarpi_sem)]\n",
    "    po_var = [sem(errpo), sem(errpo_sem), sem(tarpo_sem)]\n",
    "    ai_var = [sem(errai), sem(errai_sem), sem(tarai_sem)]\n",
    "    ao_var = [sem(errao), sem(errao_sem), sem(tarao_sem)]\n",
    "    \n",
    "    bar1 = axs[sub].bar(x[:3], pi_mean, bar_width, label='pro instimVF', yerr=pi_var, capsize=5)\n",
    "    bar2 = axs[sub].bar(x[3:6], po_mean, bar_width, label='pro outstimVF', yerr=po_var, capsize=5)\n",
    "    bar3 = axs[sub].bar(x[6:9], ai_mean, bar_width, label='anti instimVF', yerr=ai_var, capsize=5)\n",
    "    bar4 = axs[sub].bar(x[9:], ao_mean, bar_width, label='anti outstimVF', yerr=ao_var, capsize=5)\n",
    "    legend_handles.extend([bar1, bar2, bar3, bar4])\n",
    "    axs[sub].set_ylabel('isacc_err')\n",
    "    axs[sub].set_title('Sub = ' + str(this_sub))\n",
    "    axs[sub].set_xticks(x)\n",
    "    axs[sub].set_xticklabels(labels)\n",
    "        #axs[sub, day].legend()\n",
    "fig.legend(legend_handles, ['pro instimVF', 'pro outstimVF', 'anti instimVF', 'anti outstimVF'],\n",
    "           loc='upper right', bbox_to_anchor=(1.0, 1.0))\n",
    "# for ax in axs[-1]:\n",
    "#     ax.set_xticklabels(labels, rotation=45, ha='right')  # Adjust rotation angle as needed\n",
    "\n",
    "plt.subplots_adjust(right=0.85)  \n",
    "\n",
    "#fig.suptitle('Learning curve')\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1.0])  # Adjust the rect parameter as needed\n",
    "plt.savefig(save_folder + 'semantic_strategy_subjectwise.pdf', format=\"pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = [0.3, 0.8, 1.3]\n",
    "bWidth = 0.2\n",
    "X2 = [round(x + 0.1, 1) for x in X1]\n",
    "X_sum = [sum(value) for value in zip(X1, X2)]\n",
    "x_tick_pos = [round(x/2, 2) for x in X1]\n",
    "x_label_names = ['No TMS', 'MGS inVF', 'MGS outVF']\n",
    "Y1_equal = [1, 1, 1]\n",
    "Y1_specific = [1, 2, 1]\n",
    "Y1_global = [1, 2, 2]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5))\n",
    "fig.patch.set_facecolor((33/255, 33/255, 33/255))\n",
    "axes_fontsize = 12\n",
    "title_fontsize = 16\n",
    "for ii in range(3):\n",
    "    ax[ii].set_facecolor((33/255, 33/255, 33/255))\n",
    "    ax[ii].spines['bottom'].set_color('white')\n",
    "    ax[ii].spines['top'].set_color('white')\n",
    "    ax[ii].spines['left'].set_color('white')\n",
    "    ax[ii].spines['right'].set_color('white')\n",
    "    ax[ii].xaxis.label.set_color('white')\n",
    "    ax[ii].yaxis.label.set_color('white')\n",
    "    ax[ii].tick_params(axis='x', colors='white')\n",
    "    ax[ii].tick_params(axis='y', colors=(33/255, 33/255, 33/255))\n",
    "    ax[ii].set_ylim((0, 2.2))\n",
    "    ax[ii].set_xticks(X1, x_label_names, fontsize=axes_fontsize)\n",
    "    ax[ii].set_ylabel('MGS error', fontsize=axes_fontsize, labelpad=-20)\n",
    "    if ii == 0:\n",
    "        bars = ax[ii].bar(X1, Y1_equal, width = bWidth)\n",
    "        ax[ii].set_title('No effect', color = 'white', fontsize=title_fontsize)\n",
    "    elif ii == 1:\n",
    "        bars = ax[ii].bar(X1, Y1_specific, width = bWidth)\n",
    "        ax[ii].set_title('Specific', color = 'white', fontsize=title_fontsize)\n",
    "    elif ii == 2:\n",
    "        bars = ax[ii].bar(X1, Y1_global, width = bWidth)\n",
    "        ax[ii].set_title('Global', color = 'white', fontsize=title_fontsize)\n",
    "    \n",
    "    bars[0].set_color(\"#1B9E77\")\n",
    "    bars[1].set_color(\"#D95F02\")\n",
    "    bars[2].set_color(\"#7570B3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_good = df[df['subjID'] != 18]\n",
    "pro_rt = d_good[(d_good['ispro']==1) & (d_good['istms']== 0) & (d_good['instimVF'] == 1)]['isacc_rt']\n",
    "anti_rt = d_good[(d_good['ispro']==0) & (d_good['istms']== 1) & (d_good['instimVF'] == 1)]['isacc_rt']\n",
    "\n",
    "max_rt = max(np.max(pro_rt), np.max(anti_rt))\n",
    "#print(max_rt)\n",
    "nbins = 50\n",
    "t_bins = np.linspace(0, max_rt, nbins)\n",
    "t_res = 1/nbins\n",
    "p_count = np.zeros((nbins, 1))\n",
    "a_count = np.zeros((nbins, 1))\n",
    "for ii in range(nbins):\n",
    "    p_count[ii] = len(np.where((t_bins[ii]<pro_rt) & (pro_rt<t_bins[ii]+t_res))[0])\n",
    "    a_count[ii] = len(np.where((t_bins[ii]<anti_rt) & (anti_rt<t_bins[ii]+t_res))[0])\n",
    "p_count = np.cumsum(p_count)/len(pro_rt) * 100\n",
    "a_count = np.cumsum(a_count)/len(anti_rt) * 100\n",
    "print('Pro-saccade equivalence point: ' + str(int(round(t_bins[np.where(p_count < 75)[0][-1]]*1000, 0))) + 's')\n",
    "print('Anti-saccade equivalence point: ' + str(int(round(t_bins[np.where(a_count < 75)[0][-1]]*1000, 0))) + 's')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(t_bins*1000, p_count, 'b-')\n",
    "plt.plot(t_bins*1000, a_count, 'r-')\n",
    "plt.xlabel('RT (ms)')\n",
    "plt.ylabel('% Cummulative')\n",
    "plt.title('No TMS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for any existing trend in data due to eccentricity or angular width\n",
    "subjIDs = df['subjID'].unique()\n",
    "angular_width = np.zeros((len(subjIDs), 2) )\n",
    "eccs = np.zeros((len(subjIDs),2) )\n",
    "mean_err = np.zeros((len(subjIDs), 2))\n",
    "median_err = np.zeros((len(subjIDs), 2))\n",
    "var_err = np.zeros((len(subjIDs), 2))\n",
    "range_err = np.zeros((len(subjIDs), 2))\n",
    "err_met = 'isacc_err'\n",
    "\n",
    "for ii in range(len(subjIDs)):\n",
    "    this_subj_df_pro = df[(df['subjID']==subjIDs[ii]) & (df['TMS_condition']=='No TMS') & (df['ispro']==1) ]\n",
    "    this_subj_df_anti = df[(df['subjID']==subjIDs[ii]) & (df['TMS_condition']=='No TMS') & (df['ispro']==0)]\n",
    "    mean_err[ii, 0] = np.nanmean(this_subj_df_pro[err_met])\n",
    "    median_err[ii, 0] = np.nanmedian(this_subj_df_pro[err_met])\n",
    "    var_err[ii, 0] = np.nanvar(this_subj_df_pro[err_met])\n",
    "    range_err[ii, 0] = np.nanmax(this_subj_df_pro[err_met]) - np.nanmin(this_subj_df_pro[err_met])\n",
    "    mean_err[ii, 1] = np.nanmean(this_subj_df_anti[err_met])\n",
    "    median_err[ii, 1] = np.nanmedian(this_subj_df_anti[err_met])\n",
    "    var_err[ii, 1] = np.nanvar(this_subj_df_anti[err_met])\n",
    "    range_err[ii, 1] = np.nanmax(this_subj_df_anti[err_met]) - np.nanmin(this_subj_df_anti[err_met])\n",
    "    angular_width[ii, 0] = (this_subj_df_pro['TarTheta_rotated'].max() - this_subj_df_pro['TarTheta_rotated'].min()) * (180/np.pi)\n",
    "    angular_width[ii, 1] = (this_subj_df_anti['TarTheta_rotated'].max() - this_subj_df_anti['TarTheta_rotated'].min()) * (180/np.pi)\n",
    "    eccs[ii, 0] = this_subj_df_pro['TarRadius'].mean()\n",
    "    eccs[ii, 1] = this_subj_df_anti['TarRadius'].mean()\n",
    "\n",
    "fig, axs = plt.subplots(nrows = 2, ncols = 4, figsize = (20, 10))\n",
    "axs[0, 0].plot(eccs[:, 0], mean_err[:, 0], 'bo')\n",
    "axs[0, 0].plot(eccs[:, 1], mean_err[:, 1], 'ro')\n",
    "axs[0, 0].set_xlabel('eccentricity')\n",
    "axs[0, 0].set_ylabel('mean err')\n",
    "\n",
    "axs[0, 1].plot(eccs[:, 0], median_err[:, 0], 'bo')\n",
    "axs[0, 1].plot(eccs[:, 1], median_err[:, 1], 'ro')\n",
    "axs[0, 1].set_xlabel('eccentricity')\n",
    "axs[0, 1].set_ylabel('median err')\n",
    "\n",
    "axs[0, 2].plot(eccs[:, 0], var_err[:, 0], 'bo')\n",
    "axs[0, 2].plot(eccs[:, 1], var_err[:, 1], 'ro')\n",
    "axs[0, 2].set_xlabel('eccentricity')\n",
    "axs[0, 2].set_ylabel('var err')\n",
    "\n",
    "axs[0, 3].plot(eccs[:, 0], range_err[:, 0], 'bo')\n",
    "axs[0, 3].plot(eccs[:, 1], range_err[:, 1], 'ro')\n",
    "axs[0, 3].set_xlabel('eccentricity')\n",
    "axs[0, 3].set_ylabel('range err')\n",
    "\n",
    "axs[1, 0].plot(angular_width[:, 0], mean_err[:, 0], 'bo')\n",
    "axs[1, 0].plot(angular_width[:, 1], mean_err[:, 1], 'ro')\n",
    "axs[1, 0].set_xlabel('angular_width')\n",
    "axs[1, 0].set_ylabel('mean err')\n",
    "\n",
    "axs[1, 1].plot(angular_width[:, 0], median_err[:, 0], 'bo')\n",
    "axs[1, 1].plot(angular_width[:, 1], median_err[:, 1], 'ro')\n",
    "axs[1, 1].set_xlabel('angular_width')\n",
    "axs[1, 1].set_ylabel('median err')\n",
    "\n",
    "axs[1, 2].plot(angular_width[:, 0], var_err[:, 0], 'bo')\n",
    "axs[1, 2].plot(angular_width[:, 1], var_err[:, 1], 'ro')\n",
    "axs[1, 2].set_xlabel('angular_width')\n",
    "axs[1, 2].set_ylabel('var err')\n",
    "\n",
    "axs[1, 3].plot(angular_width[:, 0], range_err[:, 0], 'bo')\n",
    "axs[1, 3].plot(angular_width[:, 1], range_err[:, 1], 'ro')\n",
    "axs[1, 3].set_xlabel('angular_width')\n",
    "axs[1, 3].set_ylabel('range err')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
